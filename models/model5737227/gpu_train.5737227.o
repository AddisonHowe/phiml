Slurm job ID: 5737227
Namespace(batch_size=50, continuation=None, dt=0.1, dtype='float32', infer_noise=True, learning_rate=0.001, momentum=0.9, name='model5737227', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, optimizer='rms', outdir='out/model_training/model5737227', seed=0, sigma=0.01, training_data='data/model_training_data_2', use_gpu=True, validation_data='data/model_validation_data_2')
Using device: cuda
Using seed: 1800058982
EPOCH 1:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 683 sec]
EPOCH 2:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 684 sec]
EPOCH 3:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 681 sec]
EPOCH 4:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 684 sec]
EPOCH 5:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 655 sec]
EPOCH 6:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 618 sec]
EPOCH 7:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 542 sec]
EPOCH 8:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 9:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 10:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 11:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 542 sec]
EPOCH 12:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 13:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 14:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 15:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 541 sec]
EPOCH 16:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 17:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 18:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 19:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 20:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 540 sec]
EPOCH 21:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 22:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 23:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 24:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 25:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 26:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 27:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 28:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 29:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 30:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 31:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 32:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 33:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 34:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 35:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 36:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 37:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 539 sec]
EPOCH 38:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 39:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 40:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 538 sec]
EPOCH 41:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 42:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 43:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 44:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 45:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 46:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
EPOCH 47:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 536 sec]
EPOCH 48:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 536 sec]
EPOCH 49:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 536 sec]
EPOCH 50:
	batch 50 loss: nan
	batch 100 loss: nan
	batch 150 loss: nan
	batch 200 loss: nan
LOSS [train: nan] [valid: nan] TIME [epoch: 537 sec]
Finished training in 27705.042 seconds.
