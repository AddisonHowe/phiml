Slurm job ID: 5102135
Namespace(batch_size=50, dt=0.05, dtype='float32', learning_rate=0.01, momentum=0.9, name='model5102135', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, outdir='out/model_training/model5102135', seed=99987, sigma=0.01, training_data='data/model_training_data_2', use_gpu=True, validation_data='data/model_validation_data_2')
Using device: cuda
EPOCH 1:
	batch 50 loss: 0.025968948993831873
	batch 100 loss: 0.02411194655112922
	batch 150 loss: 0.024233594238758087
	batch 200 loss: 0.021667602313682435
LOSS [train: 0.021667602313682435] [valid: 0.020829454530515552] TIME [epoch: 503 sec]
Saving model.
EPOCH 2:
	batch 50 loss: 0.02504452696070075
	batch 100 loss: 0.02216947783716023
	batch 150 loss: 0.02175977874547243
	batch 200 loss: 0.02419553737156093
LOSS [train: 0.02419553737156093] [valid: 0.020558393194611804] TIME [epoch: 509 sec]
Saving model.
EPOCH 3:
	batch 50 loss: 0.02485281929373741
	batch 100 loss: 0.022650535451248288
	batch 150 loss: 0.021171954944729805
	batch 200 loss: 0.024203801434487103
LOSS [train: 0.024203801434487103] [valid: 0.019815052195917816] TIME [epoch: 500 sec]
Saving model.
EPOCH 4:
	batch 50 loss: 0.024206382445991038
	batch 100 loss: 0.02577395921573043
	batch 150 loss: 0.020718681188300253
	batch 200 loss: 0.02239126594737172
LOSS [train: 0.02239126594737172] [valid: 0.02079949820229861] TIME [epoch: 481 sec]
EPOCH 5:
	batch 50 loss: 0.026430382393300533
	batch 100 loss: 0.021572671886533498
	batch 150 loss: 0.021880359500646592
	batch 200 loss: 0.022743384633213282
LOSS [train: 0.022743384633213282] [valid: 0.019211857036862057] TIME [epoch: 484 sec]
Saving model.
EPOCH 6:
	batch 50 loss: 0.02070422620512545
	batch 100 loss: 0.021696622725576164
	batch 150 loss: 0.02829855751246214
	batch 200 loss: 0.023437013858929278
LOSS [train: 0.023437013858929278] [valid: 0.020446498406333072] TIME [epoch: 493 sec]
EPOCH 7:
	batch 50 loss: 0.02404689872637391
	batch 100 loss: 0.02570289831608534
	batch 150 loss: 0.02345941798761487
	batch 200 loss: 0.020128075014799834
LOSS [train: 0.020128075014799834] [valid: 0.019791053388811028] TIME [epoch: 495 sec]
EPOCH 8:
	batch 50 loss: 0.026086354181170463
	batch 100 loss: 0.023915728284046055
	batch 150 loss: 0.02159473082050681
	batch 200 loss: 0.02412769874557853
LOSS [train: 0.02412769874557853] [valid: 0.02003509686765028] TIME [epoch: 493 sec]
EPOCH 9:
	batch 50 loss: 0.02349480367265642
	batch 100 loss: 0.026750525925308466
	batch 150 loss: 0.021850795419886708
	batch 200 loss: 0.021294668735936283
LOSS [train: 0.021294668735936283] [valid: 0.019589798811648507] TIME [epoch: 493 sec]
EPOCH 10:
	batch 50 loss: 0.02124259393662214
	batch 100 loss: 0.025590749019756914
	batch 150 loss: 0.02278971708379686
	batch 200 loss: 0.0244163818936795
LOSS [train: 0.0244163818936795] [valid: 0.020072134761236763] TIME [epoch: 494 sec]
EPOCH 11:
	batch 50 loss: 0.02097029339522123
	batch 100 loss: 0.021485342178493738
	batch 150 loss: 0.0254413896240294
	batch 200 loss: 0.024466354018077254
LOSS [train: 0.024466354018077254] [valid: 0.01999177534210806] TIME [epoch: 494 sec]
EPOCH 12:
	batch 50 loss: 0.023241234943270683
	batch 100 loss: 0.022995821870863437
	batch 150 loss: 0.022123189084231852
	batch 200 loss: 0.025393620254471897
LOSS [train: 0.025393620254471897] [valid: 0.01984467260578337] TIME [epoch: 495 sec]
EPOCH 13:
	batch 50 loss: 0.023489405065774918
	batch 100 loss: 0.024491486512124537
	batch 150 loss: 0.02113827216438949
	batch 200 loss: 0.0243044379260391
LOSS [train: 0.0243044379260391] [valid: 0.01941515688619499] TIME [epoch: 496 sec]
EPOCH 14:
	batch 50 loss: 0.025165860671550036
	batch 100 loss: 0.02349669803865254
	batch 150 loss: 0.02153516105376184
	batch 200 loss: 0.021549530122429134
LOSS [train: 0.021549530122429134] [valid: 0.019965651535555178] TIME [epoch: 498 sec]
EPOCH 15:
	batch 50 loss: 0.022199409063905478
	batch 100 loss: 0.019929203214123847
	batch 150 loss: 0.024628907330334186
	batch 200 loss: 0.025600180476903916
LOSS [train: 0.025600180476903916] [valid: 0.020198755154463774] TIME [epoch: 497 sec]
EPOCH 16:
	batch 50 loss: 0.02779476121068001
	batch 100 loss: 0.02162771360017359
	batch 150 loss: 0.023339043352752924
	batch 200 loss: 0.021841020239517093
LOSS [train: 0.021841020239517093] [valid: 0.019896742657389648] TIME [epoch: 497 sec]
EPOCH 17:
	batch 50 loss: 0.02074148097075522
	batch 100 loss: 0.022706706831231712
	batch 150 loss: 0.024498621206730603
	batch 200 loss: 0.025005850223824382
LOSS [train: 0.025005850223824382] [valid: 0.01954437862877967] TIME [epoch: 497 sec]
EPOCH 18:
	batch 50 loss: 0.023809236800298096
	batch 100 loss: 0.023461486473679544
	batch 150 loss: 0.024078950472176074
	batch 200 loss: 0.02258067511022091
LOSS [train: 0.02258067511022091] [valid: 0.019938054504261043] TIME [epoch: 495 sec]
EPOCH 19:
	batch 50 loss: 0.022807793878018855
	batch 100 loss: 0.025035599451512097
	batch 150 loss: 0.021063132593408227
	batch 200 loss: 0.02382647443562746
LOSS [train: 0.02382647443562746] [valid: 0.0195250693228445] TIME [epoch: 495 sec]
EPOCH 20:
	batch 50 loss: 0.021323620062321424
	batch 100 loss: 0.021146163512021303
	batch 150 loss: 0.024210946774110197
	batch 200 loss: 0.02659283662214875
LOSS [train: 0.02659283662214875] [valid: 0.020015412746579385] TIME [epoch: 496 sec]
EPOCH 21:
	batch 50 loss: 0.02368146779946983
	batch 100 loss: 0.01965723590925336
	batch 150 loss: 0.025595439728349448
	batch 200 loss: 0.022857903307303785
LOSS [train: 0.022857903307303785] [valid: 0.020924315509425164] TIME [epoch: 497 sec]
EPOCH 22:
	batch 50 loss: 0.022164623960852625
	batch 100 loss: 0.022294910745695232
	batch 150 loss: 0.023317901026457546
	batch 200 loss: 0.0244167210906744
LOSS [train: 0.0244167210906744] [valid: 0.01974683693891469] TIME [epoch: 497 sec]
EPOCH 23:
	batch 50 loss: 0.022396695259958507
	batch 100 loss: 0.019684320194646717
	batch 150 loss: 0.024875205820426346
	batch 200 loss: 0.025534068970009684
LOSS [train: 0.025534068970009684] [valid: 0.02029081595610478] TIME [epoch: 497 sec]
EPOCH 24:
	batch 50 loss: 0.02401256650686264
	batch 100 loss: 0.021565942857414484
	batch 150 loss: 0.020355703514069318
	batch 200 loss: 0.026529255490750074
LOSS [train: 0.026529255490750074] [valid: 0.019544688197008022] TIME [epoch: 497 sec]
EPOCH 25:
	batch 50 loss: 0.02020729448646307
	batch 100 loss: 0.02093025963753462
	batch 150 loss: 0.02387297047302127
	batch 200 loss: 0.02777463458478451
LOSS [train: 0.02777463458478451] [valid: 0.019943422053862982] TIME [epoch: 498 sec]
EPOCH 26:
	batch 50 loss: 0.02579738355241716
	batch 100 loss: 0.02308185610920191
	batch 150 loss: 0.023033841382712125
	batch 200 loss: 0.021302768588066102
LOSS [train: 0.021302768588066102] [valid: 0.020207071627373806] TIME [epoch: 498 sec]
EPOCH 27:
	batch 50 loss: 0.026153192473575473
	batch 100 loss: 0.02336304359138012
	batch 150 loss: 0.021668572379276156
	batch 200 loss: 0.02144865157082677
LOSS [train: 0.02144865157082677] [valid: 0.020450304543677095] TIME [epoch: 497 sec]
EPOCH 28:
	batch 50 loss: 0.021046026488766075
	batch 100 loss: 0.022401531431823968
	batch 150 loss: 0.025538320718333125
	batch 200 loss: 0.023516060430556537
LOSS [train: 0.023516060430556537] [valid: 0.020011133696971228] TIME [epoch: 496 sec]
EPOCH 29:
	batch 50 loss: 0.02381757341325283
	batch 100 loss: 0.023871282171458005
	batch 150 loss: 0.021950766853988172
	batch 200 loss: 0.02287663591094315
LOSS [train: 0.02287663591094315] [valid: 0.01976355211130188] TIME [epoch: 495 sec]
EPOCH 30:
	batch 50 loss: 0.023469811035320164
	batch 100 loss: 0.019760466199368238
	batch 150 loss: 0.023696721913293004
	batch 200 loss: 0.025771774556487798
LOSS [train: 0.025771774556487798] [valid: 0.020115758994991968] TIME [epoch: 497 sec]
EPOCH 31:
	batch 50 loss: 0.02382058199495077
	batch 100 loss: 0.019820906165987254
	batch 150 loss: 0.02595033071935177
	batch 200 loss: 0.022060122629627584
LOSS [train: 0.022060122629627584] [valid: 0.019790692568737236] TIME [epoch: 496 sec]
EPOCH 32:
	batch 50 loss: 0.022600817447528242
	batch 100 loss: 0.023082720693200828
	batch 150 loss: 0.02339815566316247
	batch 200 loss: 0.023871936444193123
LOSS [train: 0.023871936444193123] [valid: 0.01953715911464921] TIME [epoch: 497 sec]
EPOCH 33:
	batch 50 loss: 0.021779757477343082
	batch 100 loss: 0.02781285721808672
	batch 150 loss: 0.022372938767075537
	batch 200 loss: 0.022351829130202533
LOSS [train: 0.022351829130202533] [valid: 0.020059575275323975] TIME [epoch: 495 sec]
EPOCH 34:
	batch 50 loss: 0.024462463874369858
	batch 100 loss: 0.025026886640116573
	batch 150 loss: 0.021276972461491822
	batch 200 loss: 0.022198103778064252
LOSS [train: 0.022198103778064252] [valid: 0.01999183003596651] TIME [epoch: 495 sec]
EPOCH 35:
	batch 50 loss: 0.022367228167131544
	batch 100 loss: 0.0249766138009727
	batch 150 loss: 0.023170347325503826
	batch 200 loss: 0.021225836295634508
LOSS [train: 0.021225836295634508] [valid: 0.019763150825262223] TIME [epoch: 496 sec]
EPOCH 36:
	batch 50 loss: 0.024273031763732432
	batch 100 loss: 0.02348218170925975
	batch 150 loss: 0.02289098786190152
	batch 200 loss: 0.022371341362595557
LOSS [train: 0.022371341362595557] [valid: 0.019926462926378008] TIME [epoch: 495 sec]
EPOCH 37:
	batch 50 loss: 0.021799478121101855
	batch 100 loss: 0.026979963257908822
	batch 150 loss: 0.022009015288203954
	batch 200 loss: 0.02322163224220276
LOSS [train: 0.02322163224220276] [valid: 0.019638737689820118] TIME [epoch: 495 sec]
EPOCH 38:
	batch 50 loss: 0.026179846739396453
	batch 100 loss: 0.022620126409456133
	batch 150 loss: 0.02215663144364953
	batch 200 loss: 0.021703361198306084
LOSS [train: 0.021703361198306084] [valid: 0.01961857135271809] TIME [epoch: 495 sec]
EPOCH 39:
	batch 50 loss: 0.02150650807656348
	batch 100 loss: 0.02473653629422188
	batch 150 loss: 0.0241604923363775
	batch 200 loss: 0.023526404686272144
LOSS [train: 0.023526404686272144] [valid: 0.01964488915206554] TIME [epoch: 495 sec]
EPOCH 40:
	batch 50 loss: 0.022276332173496484
	batch 100 loss: 0.020933959279209376
	batch 150 loss: 0.025376260541379453
	batch 200 loss: 0.024186157174408435
LOSS [train: 0.024186157174408435] [valid: 0.020594600562132352] TIME [epoch: 495 sec]
EPOCH 41:
	batch 50 loss: 0.02308328904211521
	batch 100 loss: 0.02501845305785537
	batch 150 loss: 0.02244373008608818
	batch 200 loss: 0.02255691890604794
LOSS [train: 0.02255691890604794] [valid: 0.019390263167588274] TIME [epoch: 482 sec]
EPOCH 42:
	batch 50 loss: 0.021569979190826417
	batch 100 loss: 0.022191830398514866
	batch 150 loss: 0.023399341125041245
	batch 200 loss: 0.024010043367743494
LOSS [train: 0.024010043367743494] [valid: 0.019964128365002883] TIME [epoch: 477 sec]
EPOCH 43:
	batch 50 loss: 0.02322722939774394
	batch 100 loss: 0.021828531008213758
	batch 150 loss: 0.02536417213268578
	batch 200 loss: 0.02243606104515493
LOSS [train: 0.02243606104515493] [valid: 0.02009065297121803] TIME [epoch: 479 sec]
EPOCH 44:
	batch 50 loss: 0.02497515931725502
	batch 100 loss: 0.020948820794001222
	batch 150 loss: 0.024242133535444736
	batch 200 loss: 0.02160981049761176
LOSS [train: 0.02160981049761176] [valid: 0.019481022520631087] TIME [epoch: 478 sec]
EPOCH 45:
	batch 50 loss: 0.022702484568580986
	batch 100 loss: 0.023119159620255233
	batch 150 loss: 0.019739097971469163
	batch 200 loss: 0.02536176038905978
LOSS [train: 0.02536176038905978] [valid: 0.019735262946536145] TIME [epoch: 477 sec]
EPOCH 46:
	batch 50 loss: 0.022882023323327304
	batch 100 loss: 0.02393531985580921
	batch 150 loss: 0.022253111321479082
	batch 200 loss: 0.025171631649136543
LOSS [train: 0.025171631649136543] [valid: 0.019906142962766656] TIME [epoch: 476 sec]
EPOCH 47:
	batch 50 loss: 0.02545767905190587
	batch 100 loss: 0.022846647072583437
	batch 150 loss: 0.023011404257267713
	batch 200 loss: 0.02111173728480935
LOSS [train: 0.02111173728480935] [valid: 0.02036238545648909] TIME [epoch: 479 sec]
EPOCH 48:
	batch 50 loss: 0.025217907698825003
	batch 100 loss: 0.0213184286467731
	batch 150 loss: 0.024396083438768982
	batch 200 loss: 0.02068447709083557
LOSS [train: 0.02068447709083557] [valid: 0.02042287665923747] TIME [epoch: 478 sec]
EPOCH 49:
	batch 50 loss: 0.024339830074459314
	batch 100 loss: 0.024091786397621037
	batch 150 loss: 0.022555249324068428
	batch 200 loss: 0.02168126174248755
LOSS [train: 0.02168126174248755] [valid: 0.019828592128275584] TIME [epoch: 478 sec]
EPOCH 50:
	batch 50 loss: 0.02321581996977329
	batch 100 loss: 0.024003827963024377
	batch 150 loss: 0.020804360639303923
	batch 200 loss: 0.025219419095665215
LOSS [train: 0.025219419095665215] [valid: 0.01949516975970861] TIME [epoch: 477 sec]
Finished training in 24610.698 seconds.
