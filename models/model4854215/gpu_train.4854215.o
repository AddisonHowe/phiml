Slurm job ID: 4854215
Namespace(batch_size=50, dt=0.01, dtype='float32', learning_rate=0.01, momentum=0.9, name='model4854215', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, outdir='out/model_training/model4854215', seed=99987, sigma=0.001, training_data='data/model_training_data', use_gpu=True, validation_data='data/model_validation_data')
Using device: cuda
EPOCH 1:
	batch 50 loss: 0.002137690064264461
	batch 100 loss: 0.0022065635561011733
	batch 150 loss: 0.002093230405007489
	batch 200 loss: 0.0022621440957300365
LOSS [train: 0.0022621440957300365] [valid: 0.0016717928180999782] TIME [epoch: 248 sec]
Saving model.
EPOCH 2:
	batch 50 loss: 0.0021937454491853716
	batch 100 loss: 0.0020565909845754503
	batch 150 loss: 0.0018543580174446106
	batch 200 loss: 0.0019957978487946094
LOSS [train: 0.0019957978487946094] [valid: 0.0015875294042871247] TIME [epoch: 249 sec]
Saving model.
EPOCH 3:
	batch 50 loss: 0.00200821875478141
	batch 100 loss: 0.001957846935838461
	batch 150 loss: 0.0017054970451863482
	batch 200 loss: 0.0020658732519950717
LOSS [train: 0.0020658732519950717] [valid: 0.001532757316393448] TIME [epoch: 250 sec]
Saving model.
EPOCH 4:
	batch 50 loss: 0.0019580693473108114
	batch 100 loss: 0.0019207953999284654
	batch 150 loss: 0.0017026299179997296
	batch 200 loss: 0.0019191441498696805
LOSS [train: 0.0019191441498696805] [valid: 0.0014941576495402843] TIME [epoch: 250 sec]
Saving model.
EPOCH 5:
	batch 50 loss: 0.002001013027038425
	batch 100 loss: 0.001710875614080578
	batch 150 loss: 0.0018270729039795697
	batch 200 loss: 0.0017981738579692318
LOSS [train: 0.0017981738579692318] [valid: 0.001465565253602108] TIME [epoch: 248 sec]
Saving model.
EPOCH 6:
	batch 50 loss: 0.0017183331062551588
	batch 100 loss: 0.0017209972895216197
	batch 150 loss: 0.0019079443847294898
	batch 200 loss: 0.0018718158057890832
LOSS [train: 0.0018718158057890832] [valid: 0.0014444611060753232] TIME [epoch: 248 sec]
Saving model.
EPOCH 7:
	batch 50 loss: 0.0018832898215623572
	batch 100 loss: 0.0017793372634332628
	batch 150 loss: 0.0016551939910277723
	batch 200 loss: 0.0018136649776715784
LOSS [train: 0.0018136649776715784] [valid: 0.001428230795742517] TIME [epoch: 240 sec]
Saving model.
EPOCH 8:
	batch 50 loss: 0.001794657305581495
	batch 100 loss: 0.001735134351765737
	batch 150 loss: 0.0017623650026507675
	batch 200 loss: 0.0017733711074106396
LOSS [train: 0.0017733711074106396] [valid: 0.0014160501496614112] TIME [epoch: 238 sec]
Saving model.
EPOCH 9:
	batch 50 loss: 0.001830376225989312
	batch 100 loss: 0.0017765524052083493
	batch 150 loss: 0.0017498478037305176
	batch 200 loss: 0.0016585632000351324
LOSS [train: 0.0016585632000351324] [valid: 0.0014066574951963654] TIME [epoch: 236 sec]
Saving model.
EPOCH 10:
	batch 50 loss: 0.0017873440543189644
	batch 100 loss: 0.0017892515659332275
	batch 150 loss: 0.0017882926610764116
	batch 200 loss: 0.0016119841858744622
LOSS [train: 0.0016119841858744622] [valid: 0.0013996802018179247] TIME [epoch: 236 sec]
Saving model.
EPOCH 11:
	batch 50 loss: 0.0016004636243451386
	batch 100 loss: 0.0017760431487113238
	batch 150 loss: 0.0017207443260122092
	batch 200 loss: 0.0018497232918161899
LOSS [train: 0.0018497232918161899] [valid: 0.0013944305240632577] TIME [epoch: 241 sec]
Saving model.
EPOCH 12:
	batch 50 loss: 0.001612324301386252
	batch 100 loss: 0.0016841925022890792
	batch 150 loss: 0.0018210708838887512
	batch 200 loss: 0.0018064704036805778
LOSS [train: 0.0018064704036805778] [valid: 0.0013903259258465064] TIME [epoch: 245 sec]
Saving model.
EPOCH 13:
	batch 50 loss: 0.001715892810607329
	batch 100 loss: 0.0017512340372195468
	batch 150 loss: 0.0017788795748492703
	batch 200 loss: 0.001659676523413509
LOSS [train: 0.001659676523413509] [valid: 0.0013874849625911641] TIME [epoch: 245 sec]
Saving model.
EPOCH 14:
	batch 50 loss: 0.0017551666096551344
	batch 100 loss: 0.0016877323889639229
	batch 150 loss: 0.0017328305507544428
	batch 200 loss: 0.0017163540970068425
LOSS [train: 0.0017163540970068425] [valid: 0.0013852156709617703] TIME [epoch: 245 sec]
Saving model.
EPOCH 15:
	batch 50 loss: 0.0015828154189512134
	batch 100 loss: 0.0017412103770766407
	batch 150 loss: 0.0016905313124880195
	batch 200 loss: 0.0018666664825286716
LOSS [train: 0.0018666664825286716] [valid: 0.0013837254841443307] TIME [epoch: 245 sec]
Saving model.
EPOCH 16:
	batch 50 loss: 0.0017899970163125544
	batch 100 loss: 0.0016285547718871386
	batch 150 loss: 0.0017200739902909845
	batch 200 loss: 0.0017345535417553038
LOSS [train: 0.0017345535417553038] [valid: 0.0013826496876693758] TIME [epoch: 246 sec]
Saving model.
EPOCH 17:
	batch 50 loss: 0.0017633935250341891
	batch 100 loss: 0.001593868713825941
	batch 150 loss: 0.001757625094614923
	batch 200 loss: 0.001751816378091462
LOSS [train: 0.001751816378091462] [valid: 0.001381831631078967] TIME [epoch: 246 sec]
Saving model.
EPOCH 18:
	batch 50 loss: 0.0017808850994333624
	batch 100 loss: 0.0015685867518186569
	batch 150 loss: 0.001798341586254537
	batch 200 loss: 0.0017140074435155839
LOSS [train: 0.0017140074435155839] [valid: 0.001381333003155305] TIME [epoch: 246 sec]
Saving model.
EPOCH 19:
	batch 50 loss: 0.001678321771323681
	batch 100 loss: 0.0018097867083270102
	batch 150 loss: 0.0016791116166859866
	batch 200 loss: 0.0016904592013452203
LOSS [train: 0.0016904592013452203] [valid: 0.001381066827889299] TIME [epoch: 246 sec]
Saving model.
EPOCH 20:
	batch 50 loss: 0.0017979387124069034
	batch 100 loss: 0.001537316458998248
	batch 150 loss: 0.0018738392333034425
	batch 200 loss: 0.0016457140969578176
LOSS [train: 0.0016457140969578176] [valid: 0.0013809063958736564] TIME [epoch: 246 sec]
Saving model.
EPOCH 21:
	batch 50 loss: 0.0016451645235065371
	batch 100 loss: 0.0017175338987726718
	batch 150 loss: 0.0016482889535836876
	batch 200 loss: 0.0018414204521104694
LOSS [train: 0.0018414204521104694] [valid: 0.0013807481600451865] TIME [epoch: 246 sec]
Saving model.
EPOCH 22:
	batch 50 loss: 0.0017086032312363386
	batch 100 loss: 0.0017793816269841044
	batch 150 loss: 0.0016258167906198651
	batch 200 loss: 0.0017369584972038866
LOSS [train: 0.0017369584972038866] [valid: 0.0013808702080496005] TIME [epoch: 244 sec]
EPOCH 23:
	batch 50 loss: 0.0016740091983228921
	batch 100 loss: 0.0017189581680577249
	batch 150 loss: 0.001659822737565264
	batch 200 loss: 0.0017964363156352191
LOSS [train: 0.0017964363156352191] [valid: 0.00138073232780395] TIME [epoch: 245 sec]
Saving model.
EPOCH 24:
	batch 50 loss: 0.001696798267075792
	batch 100 loss: 0.001612149957800284
	batch 150 loss: 0.001723619893891737
	batch 200 loss: 0.0018158322456292809
LOSS [train: 0.0018158322456292809] [valid: 0.0013809285734168951] TIME [epoch: 245 sec]
EPOCH 25:
	batch 50 loss: 0.0018499011802487076
	batch 100 loss: 0.0016793642390985043
	batch 150 loss: 0.0016447963390965015
	batch 200 loss: 0.0016733277880121022
LOSS [train: 0.0016733277880121022] [valid: 0.001380814985895995] TIME [epoch: 245 sec]
EPOCH 26:
	batch 50 loss: 0.0016042072675190866
	batch 100 loss: 0.0016549223754554988
	batch 150 loss: 0.0017781751428265124
	batch 200 loss: 0.001809359391918406
LOSS [train: 0.001809359391918406] [valid: 0.0013811512420033977] TIME [epoch: 244 sec]
EPOCH 27:
	batch 50 loss: 0.0017540056409779937
	batch 100 loss: 0.0016099159774603322
	batch 150 loss: 0.0016889145993627607
	batch 200 loss: 0.0017933137028012425
LOSS [train: 0.0017933137028012425] [valid: 0.001380982258797303] TIME [epoch: 243 sec]
EPOCH 28:
	batch 50 loss: 0.0017679740418680013
	batch 100 loss: 0.0017801939137279987
	batch 150 loss: 0.0015935133607126771
	batch 200 loss: 0.0017041133216116578
LOSS [train: 0.0017041133216116578] [valid: 0.0013811458000115332] TIME [epoch: 244 sec]
EPOCH 29:
	batch 50 loss: 0.0017970507370773702
	batch 100 loss: 0.0016498865972971544
	batch 150 loss: 0.0016006489214487373
	batch 200 loss: 0.0017978738760575652
LOSS [train: 0.0017978738760575652] [valid: 0.001381404627742692] TIME [epoch: 244 sec]
EPOCH 30:
	batch 50 loss: 0.0015966384566854686
	batch 100 loss: 0.0017885962838772684
	batch 150 loss: 0.0016432979970704765
	batch 200 loss: 0.0018167904345318675
LOSS [train: 0.0018167904345318675] [valid: 0.0013812345694532268] TIME [epoch: 244 sec]
EPOCH 31:
	batch 50 loss: 0.0017538077640347183
	batch 100 loss: 0.0016075120191089809
	batch 150 loss: 0.0016611427592579276
	batch 200 loss: 0.0018225648254156113
LOSS [train: 0.0018225648254156113] [valid: 0.0013815458634477789] TIME [epoch: 242 sec]
EPOCH 32:
	batch 50 loss: 0.0016796423227060586
	batch 100 loss: 0.0018628464185167105
	batch 150 loss: 0.0016261823964305222
	batch 200 loss: 0.0016766067023854703
LOSS [train: 0.0016766067023854703] [valid: 0.001381559103235001] TIME [epoch: 234 sec]
EPOCH 33:
	batch 50 loss: 0.0018545107904355974
	batch 100 loss: 0.001589884228305891
	batch 150 loss: 0.0016773146740160882
	batch 200 loss: 0.0017229584080632775
LOSS [train: 0.0017229584080632775] [valid: 0.0013815821295793285] TIME [epoch: 236 sec]
EPOCH 34:
	batch 50 loss: 0.0017585716804023833
	batch 100 loss: 0.0017672555684112013
	batch 150 loss: 0.0016483219317160547
	batch 200 loss: 0.0016707197192590683
LOSS [train: 0.0016707197192590683] [valid: 0.0013816037821622255] TIME [epoch: 235 sec]
EPOCH 35:
	batch 50 loss: 0.0016352342709433287
	batch 100 loss: 0.0017542912892531603
	batch 150 loss: 0.001627842579036951
	batch 200 loss: 0.0018274239858146757
LOSS [train: 0.0018274239858146757] [valid: 0.0013815929965251901] TIME [epoch: 235 sec]
EPOCH 36:
	batch 50 loss: 0.0017444229230750353
	batch 100 loss: 0.0016845681588165463
	batch 150 loss: 0.0016637886269018055
	batch 200 loss: 0.0017517787171527743
LOSS [train: 0.0017517787171527743] [valid: 0.0013818675910746] TIME [epoch: 246 sec]
EPOCH 37:
	batch 50 loss: 0.0016664895263966172
	batch 100 loss: 0.0017958568199537694
	batch 150 loss: 0.0017554434115299956
	batch 200 loss: 0.001626893056090921
LOSS [train: 0.001626893056090921] [valid: 0.0013818228955339389] TIME [epoch: 246 sec]
EPOCH 38:
	batch 50 loss: 0.0015595310064963996
	batch 100 loss: 0.0017159076815005392
	batch 150 loss: 0.001725890904199332
	batch 200 loss: 0.0018434534757398068
LOSS [train: 0.0018434534757398068] [valid: 0.0013818721262699304] TIME [epoch: 245 sec]
EPOCH 39:
	batch 50 loss: 0.0016498743346892296
	batch 100 loss: 0.0016197141516022383
	batch 150 loss: 0.0017510800203308463
	batch 200 loss: 0.0018238469387870282
LOSS [train: 0.0018238469387870282] [valid: 0.0013817492618121226] TIME [epoch: 245 sec]
EPOCH 40:
	batch 50 loss: 0.0016576431406429037
	batch 100 loss: 0.0018081571639049798
	batch 150 loss: 0.0017476432607509197
	batch 200 loss: 0.001631388337118551
LOSS [train: 0.001631388337118551] [valid: 0.0013818452576742856] TIME [epoch: 245 sec]
EPOCH 41:
	batch 50 loss: 0.0016714731638785452
	batch 100 loss: 0.0017342920566443354
	batch 150 loss: 0.001854893781710416
	batch 200 loss: 0.001583545058965683
LOSS [train: 0.001583545058965683] [valid: 0.0013818491885710198] TIME [epoch: 245 sec]
EPOCH 42:
	batch 50 loss: 0.0016673203324899077
	batch 100 loss: 0.0017245599953457714
	batch 150 loss: 0.0017427218321245165
	batch 200 loss: 0.0017101489182095974
LOSS [train: 0.0017101489182095974] [valid: 0.0013819909138571044] TIME [epoch: 242 sec]
EPOCH 43:
	batch 50 loss: 0.0017938633693847805
	batch 100 loss: 0.0016760256525594742
	batch 150 loss: 0.001653573918156326
	batch 200 loss: 0.0017211535025853663
LOSS [train: 0.0017211535025853663] [valid: 0.0013819796506747176] TIME [epoch: 237 sec]
EPOCH 44:
	batch 50 loss: 0.0017475723795359955
	batch 100 loss: 0.0018001920462120324
	batch 150 loss: 0.0016749673406593502
	batch 200 loss: 0.0016218972182832658
LOSS [train: 0.0016218972182832658] [valid: 0.0013819864342622169] TIME [epoch: 237 sec]
EPOCH 45:
	batch 50 loss: 0.0016928192286286502
	batch 100 loss: 0.0015985829895362258
	batch 150 loss: 0.001734757168451324
	batch 200 loss: 0.0018183590308763087
LOSS [train: 0.0018183590308763087] [valid: 0.0013819851869508663] TIME [epoch: 237 sec]
EPOCH 46:
	batch 50 loss: 0.0016673577786423266
	batch 100 loss: 0.0018288509064586832
	batch 150 loss: 0.0015638915647286922
	batch 200 loss: 0.0017846475378610193
LOSS [train: 0.0017846475378610193] [valid: 0.0013818678467941935] TIME [epoch: 237 sec]
EPOCH 47:
	batch 50 loss: 0.0016472960432292894
	batch 100 loss: 0.001743861036375165
	batch 150 loss: 0.001779809050494805
	batch 200 loss: 0.0016733030241448431
LOSS [train: 0.0016733030241448431] [valid: 0.0013821149870940038] TIME [epoch: 237 sec]
EPOCH 48:
	batch 50 loss: 0.0016007327008992433
	batch 100 loss: 0.0017240744025912135
	batch 150 loss: 0.0018635489570442588
	batch 200 loss: 0.001656394413439557
LOSS [train: 0.001656394413439557] [valid: 0.0013820103306594925] TIME [epoch: 237 sec]
EPOCH 49:
	batch 50 loss: 0.0016667482070624828
	batch 100 loss: 0.0017591919319238515
	batch 150 loss: 0.0017293940403033047
	batch 200 loss: 0.001688801881391555
LOSS [train: 0.001688801881391555] [valid: 0.001382293217284314] TIME [epoch: 237 sec]
EPOCH 50:
	batch 50 loss: 0.0017452763370238245
	batch 100 loss: 0.0015972299082204699
	batch 150 loss: 0.0016799815045669675
	batch 200 loss: 0.001822003138368018
LOSS [train: 0.001822003138368018] [valid: 0.0013821230628309421] TIME [epoch: 237 sec]
Finished training in 12129.540 seconds.
Saving training and validation loss history...
Done!
