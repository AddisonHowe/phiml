Slurm job ID: 7293222
args: Namespace(batch_size=25, continuation=None, dt=0.1, dtype='float32', final_act='None', hidden_acts=['softplus'], hidden_dims=[16, 32, 32, 16], infer_noise=True, layer_normalize=False, learning_rate=0.001, loss='mcd', momentum=0.9, name='model7293222', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, optimizer='rms', outdir='out/model_training/model7293222', plot=True, seed=0, sigma=0.01, signal_function='jump', timestamp=False, training_data='data/model_training_data_2', use_gpu=False, validation_data='data/model_validation_data_2', weight_decay=0.0)
Using device: cpu
Using seed: 3142990846
EPOCH 1:
	batch 25 loss: 0.41226969957351683
	batch 50 loss: 0.0648284649848938
	batch 75 loss: 0.02865193147212267
	batch 100 loss: 0.02148259777575731
	batch 125 loss: 0.022517637703567742
	batch 150 loss: 0.02466809744015336
	batch 175 loss: 0.02030018711462617
	batch 200 loss: 0.020350357219576835
	batch 225 loss: 0.028553025759756566
	batch 250 loss: 0.02191208817064762
	batch 275 loss: 0.01946039590984583
	batch 300 loss: 0.025076661743223667
	batch 325 loss: 0.02137052536010742
	batch 350 loss: 0.023922718800604342
	batch 375 loss: 0.020529004707932473
	batch 400 loss: 0.022276435047388077
LOSS [train: 0.022276435047388077] [valid: 0.018648215995926875] TIME [epoch: 2.15e+03 sec]
Saving model.
EPOCH 2:
	batch 25 loss: 0.01987738586962223
	batch 50 loss: 0.02639952000230551
	batch 75 loss: 0.027154140304774046
	batch 100 loss: 0.024352823980152608
	batch 125 loss: 0.017976679131388663
	batch 150 loss: 0.017788514345884323
	batch 175 loss: 0.021429619658738373
	batch 200 loss: 0.024583012256771328
	batch 225 loss: 0.016783761177212
	batch 250 loss: 0.025988157372921705
	batch 275 loss: 0.018545515965670348
	batch 300 loss: 0.01994819665327668
	batch 325 loss: 0.020671044755727053
	batch 350 loss: 0.015711936466395855
	batch 375 loss: 0.02859764402732253
	batch 400 loss: 0.027250719219446183
LOSS [train: 0.027250719219446183] [valid: 0.01994396886633088] TIME [epoch: 2.13e+03 sec]
EPOCH 3:
	batch 25 loss: 0.019962477553635834
	batch 50 loss: 0.017917584665119647
	batch 75 loss: 0.014032948669046164
	batch 100 loss: 0.024410195853561162
	batch 125 loss: 0.020254776794463396
	batch 150 loss: 0.02417454306036234
	batch 175 loss: 0.024070724174380304
	batch 200 loss: 0.029879949297755958
	batch 225 loss: 0.029694543927907945
	batch 250 loss: 0.019954283684492112
	batch 275 loss: 0.018913722429424525
	batch 300 loss: 0.01799717517569661
	batch 325 loss: 0.0238782786950469
	batch 350 loss: 0.016786429286003112
	batch 375 loss: 0.020778106730431317
	batch 400 loss: 0.019313958510756492
LOSS [train: 0.019313958510756492] [valid: 0.017078432784425484] TIME [epoch: 2.11e+03 sec]
Saving model.
EPOCH 4:
	batch 25 loss: 0.021704850122332572
	batch 50 loss: 0.01826606772840023
	batch 75 loss: 0.020887810895219447
	batch 100 loss: 0.028013142533600332
	batch 125 loss: 0.0265659424290061
	batch 150 loss: 0.019546545390039683
	batch 175 loss: 0.019606894906610252
	batch 200 loss: 0.020379064213484524
	batch 225 loss: 0.02176364779472351
	batch 250 loss: 0.024522224329411983
	batch 275 loss: 0.01787687899544835
	batch 300 loss: 0.01932524478062987
	batch 325 loss: 0.018219752870500087
	batch 350 loss: 0.015754634123295544
	batch 375 loss: 0.021432384569197892
	batch 400 loss: 0.014685039930045605
LOSS [train: 0.014685039930045605] [valid: 0.01860418916536825] TIME [epoch: 2.15e+03 sec]
EPOCH 5:
	batch 25 loss: 0.0204497186653316
	batch 50 loss: 0.0162373517639935
	batch 75 loss: 0.02050373325124383
	batch 100 loss: 0.02624765917658806
	batch 125 loss: 0.024135940447449683
	batch 150 loss: 0.01914720142260194
	batch 175 loss: 0.016042881961911917
	batch 200 loss: 0.020245946887880565
	batch 225 loss: 0.01535914202220738
	batch 250 loss: 0.020959998052567243
	batch 275 loss: 0.025523771420121192
	batch 300 loss: 0.01926905205473304
	batch 325 loss: 0.021972236577421426
	batch 350 loss: 0.021317816451191903
	batch 375 loss: 0.02292520422488451
	batch 400 loss: 0.01985157320275903
LOSS [train: 0.01985157320275903] [valid: 0.017299878562334926] TIME [epoch: 2.14e+03 sec]
EPOCH 6:
	batch 25 loss: 0.016564127523452044
	batch 50 loss: 0.023731100037693978
	batch 75 loss: 0.022173868659883737
	batch 100 loss: 0.020108789019286633
	batch 125 loss: 0.02304641790688038
	batch 150 loss: 0.023722626157104968
	batch 175 loss: 0.017234076038002966
	batch 200 loss: 0.023038613870739938
	batch 225 loss: 0.01808130128309131
	batch 250 loss: 0.019940407052636146
	batch 275 loss: 0.03041818980127573
	batch 300 loss: 0.021684008818119764
	batch 325 loss: 0.018774549420922996
	batch 350 loss: 0.0190460660867393
	batch 375 loss: 0.01891487469896674
	batch 400 loss: 0.013078120201826096
LOSS [train: 0.013078120201826096] [valid: 0.0181081245928605] TIME [epoch: 2.15e+03 sec]
EPOCH 7:
	batch 25 loss: 0.020139507092535494
	batch 50 loss: 0.018369236271828415
	batch 75 loss: 0.020563271101564168
	batch 100 loss: 0.0157592417858541
	batch 125 loss: 0.018212983552366495
	batch 150 loss: 0.02111575983464718
	batch 175 loss: 0.021054794024676086
	batch 200 loss: 0.025945188496261835
	batch 225 loss: 0.018470945078879596
	batch 250 loss: 0.021221780087798833
	batch 275 loss: 0.01966451123356819
	batch 300 loss: 0.024447736367583274
	batch 325 loss: 0.02570421256124973
	batch 350 loss: 0.01991069108247757
	batch 375 loss: 0.019060089010745285
	batch 400 loss: 0.016316920220851898
LOSS [train: 0.016316920220851898] [valid: 0.01747380738221788] TIME [epoch: 2.06e+03 sec]
EPOCH 8:
	batch 25 loss: 0.019447959698736667
	batch 50 loss: 0.025492945052683354
	batch 75 loss: 0.020042974650859833
	batch 100 loss: 0.021331697031855584
	batch 125 loss: 0.018638405911624432
	batch 150 loss: 0.017365340031683444
	batch 175 loss: 0.02129479415714741
	batch 200 loss: 0.01691498398780823
	batch 225 loss: 0.021412287782877685
	batch 250 loss: 0.01842790938913822
	batch 275 loss: 0.020912934243679047
	batch 300 loss: 0.020921851862221955
	batch 325 loss: 0.023400160633027554
	batch 350 loss: 0.021863059010356664
	batch 375 loss: 0.023373047187924385
	batch 400 loss: 0.021482962369918823
LOSS [train: 0.021482962369918823] [valid: 0.018442599911941214] TIME [epoch: 1.96e+03 sec]
EPOCH 9:
	batch 25 loss: 0.02279235526919365
	batch 50 loss: 0.020665335562080146
	batch 75 loss: 0.01684925438836217
	batch 100 loss: 0.015043744556605817
	batch 125 loss: 0.023874203488230706
	batch 150 loss: 0.021238274183124305
	batch 175 loss: 0.018434384912252424
	batch 200 loss: 0.01893146591261029
	batch 225 loss: 0.021306243799626826
	batch 250 loss: 0.024635637104511263
	batch 275 loss: 0.018126491494476794
	batch 300 loss: 0.019650392830371857
	batch 325 loss: 0.01792626768350601
	batch 350 loss: 0.020501122940331698
	batch 375 loss: 0.020494727566838265
	batch 400 loss: 0.020734696201980114
LOSS [train: 0.020734696201980114] [valid: 0.01748149574971952] TIME [epoch: 1.99e+03 sec]
EPOCH 10:
	batch 25 loss: 0.019428681544959546
	batch 50 loss: 0.02238035833463073
	batch 75 loss: 0.01798024319112301
	batch 100 loss: 0.024251028653234242
	batch 125 loss: 0.02552073387429118
	batch 150 loss: 0.02427418638020754
	batch 175 loss: 0.01568999180570245
	batch 200 loss: 0.019523488972336054
	batch 225 loss: 0.020767120104283096
	batch 250 loss: 0.017120653707534076
	batch 275 loss: 0.02007910780608654
	batch 300 loss: 0.016441083950921892
	batch 325 loss: 0.02080204714089632
	batch 350 loss: 0.019687615744769574
	batch 375 loss: 0.020057241274043916
	batch 400 loss: 0.025358477085828782
LOSS [train: 0.025358477085828782] [valid: 0.01783454692631494] TIME [epoch: 1.77e+03 sec]
EPOCH 11:
	batch 25 loss: 0.01782974561676383
	batch 50 loss: 0.02521382462233305
	batch 75 loss: 0.02754980057477951
	batch 100 loss: 0.019735511001199482
	batch 125 loss: 0.01761232689023018
	batch 150 loss: 0.021763822222128512
	batch 175 loss: 0.022695333659648896
	batch 200 loss: 0.014087120164185762
	batch 225 loss: 0.025935397520661353
	batch 250 loss: 0.021555597707629204
	batch 275 loss: 0.024521041233092546
	batch 300 loss: 0.020362530648708344
	batch 325 loss: 0.016850413251668216
	batch 350 loss: 0.014824664499610663
	batch 375 loss: 0.013793420530855655
	batch 400 loss: 0.018754956778138876
LOSS [train: 0.018754956778138876] [valid: 0.01716598887918129] TIME [epoch: 1.45e+03 sec]
EPOCH 12:
	batch 25 loss: 0.02170593123883009
	batch 50 loss: 0.02427931733429432
	batch 75 loss: 0.02170143960043788
	batch 100 loss: 0.020992234833538532
	batch 125 loss: 0.01921196423470974
	batch 150 loss: 0.017287272289395333
	batch 175 loss: 0.020473079048097132
	batch 200 loss: 0.017668796889483928
	batch 225 loss: 0.024634390007704496
	batch 250 loss: 0.017335037756711243
	batch 275 loss: 0.01948556987568736
	batch 300 loss: 0.02172637853771448
	batch 325 loss: 0.019223494324833154
	batch 350 loss: 0.01573931930586696
	batch 375 loss: 0.023004327565431595
	batch 400 loss: 0.02015507934615016
LOSS [train: 0.02015507934615016] [valid: 0.01759876119576802] TIME [epoch: 1.45e+03 sec]
EPOCH 13:
	batch 25 loss: 0.0200720077753067
	batch 50 loss: 0.01697272539138794
	batch 75 loss: 0.025242157019674777
	batch 100 loss: 0.022067144587635992
	batch 125 loss: 0.020065884739160537
	batch 150 loss: 0.019496234357357024
	batch 175 loss: 0.022306985659524797
	batch 200 loss: 0.019430723004043103
	batch 225 loss: 0.02519757965579629
	batch 250 loss: 0.019221663270145656
	batch 275 loss: 0.02153215754777193
	batch 300 loss: 0.01773028302937746
	batch 325 loss: 0.019591637179255484
	batch 350 loss: 0.018879782501608135
	batch 375 loss: 0.021147891124710442
	batch 400 loss: 0.02094697445631027
LOSS [train: 0.02094697445631027] [valid: 0.017784243448719886] TIME [epoch: 1.45e+03 sec]
EPOCH 14:
	batch 25 loss: 0.02460050879046321
	batch 50 loss: 0.018726061023771765
	batch 75 loss: 0.01603777885437012
	batch 100 loss: 0.02444038643501699
	batch 125 loss: 0.017236745953559875
	batch 150 loss: 0.021920814346522093
	batch 175 loss: 0.0183200291916728
	batch 200 loss: 0.023671841956675054
	batch 225 loss: 0.018412113972008228
	batch 250 loss: 0.023297449480742215
	batch 275 loss: 0.020752786695957183
	batch 300 loss: 0.021259634867310525
	batch 325 loss: 0.01657380061224103
	batch 350 loss: 0.019744816645979883
	batch 375 loss: 0.01776857625693083
	batch 400 loss: 0.021858435049653055
LOSS [train: 0.021858435049653055] [valid: 0.01860109727786039] TIME [epoch: 1.45e+03 sec]
EPOCH 15:
	batch 25 loss: 0.018801049403846262
	batch 50 loss: 0.02002654902637005
	batch 75 loss: 0.027507774289697407
	batch 100 loss: 0.020269526448100806
	batch 125 loss: 0.021048981770873068
	batch 150 loss: 0.019329967740923167
	batch 175 loss: 0.023938438929617403
	batch 200 loss: 0.018375380765646696
	batch 225 loss: 0.016526140663772823
	batch 250 loss: 0.02070575837045908
	batch 275 loss: 0.016733695585280657
	batch 300 loss: 0.02288706835359335
	batch 325 loss: 0.01830356424674392
	batch 350 loss: 0.018381916880607606
	batch 375 loss: 0.02224641451612115
	batch 400 loss: 0.01819475095719099
LOSS [train: 0.01819475095719099] [valid: 0.01804597412071113] TIME [epoch: 1.45e+03 sec]
EPOCH 16:
	batch 25 loss: 0.02090420302003622
	batch 50 loss: 0.019132350161671637
	batch 75 loss: 0.018499379307031633
	batch 100 loss: 0.01816194238141179
	batch 125 loss: 0.018396302852779628
	batch 150 loss: 0.02178558673709631
	batch 175 loss: 0.016986999474465848
	batch 200 loss: 0.019235657062381506
	batch 225 loss: 0.021662250496447086
	batch 250 loss: 0.022025750912725926
	batch 275 loss: 0.02089656801894307
	batch 300 loss: 0.01615360477939248
	batch 325 loss: 0.022753684483468532
	batch 350 loss: 0.017379132052883505
	batch 375 loss: 0.024203153997659682
	batch 400 loss: 0.023293463289737703
LOSS [train: 0.023293463289737703] [valid: 0.017953320934126774] TIME [epoch: 1.45e+03 sec]
EPOCH 17:
	batch 25 loss: 0.021247238535434008
	batch 50 loss: 0.022190571203827857
	batch 75 loss: 0.022631261870265006
	batch 100 loss: 0.025530213974416256
	batch 125 loss: 0.018498942591249942
	batch 150 loss: 0.01769984794780612
	batch 175 loss: 0.021495563462376594
	batch 200 loss: 0.018524463437497616
	batch 225 loss: 0.021196801271289586
	batch 250 loss: 0.024653188101947308
	batch 275 loss: 0.022609739266335964
	batch 300 loss: 0.019650089424103498
	batch 325 loss: 0.020498121082782747
	batch 350 loss: 0.01509207209572196
	batch 375 loss: 0.018222150206565858
	batch 400 loss: 0.01623812748119235
LOSS [train: 0.01623812748119235] [valid: 0.01768284117230602] TIME [epoch: 1.45e+03 sec]
EPOCH 18:
	batch 25 loss: 0.017392199002206326
	batch 50 loss: 0.022371644116938115
	batch 75 loss: 0.01925626389682293
	batch 100 loss: 0.020803387369960548
	batch 125 loss: 0.02007455799728632
	batch 150 loss: 0.023940519038587807
	batch 175 loss: 0.019514372944831847
	batch 200 loss: 0.016323574427515267
	batch 225 loss: 0.02031878624111414
	batch 250 loss: 0.020172038525342943
	batch 275 loss: 0.0202506441809237
	batch 300 loss: 0.022946891728788613
	batch 325 loss: 0.016813167482614518
	batch 350 loss: 0.021911887759342788
	batch 375 loss: 0.02071904210373759
	batch 400 loss: 0.023871544618159532
LOSS [train: 0.023871544618159532] [valid: 0.018321534348312223] TIME [epoch: 1.51e+03 sec]
EPOCH 19:
	batch 25 loss: 0.021642859131097793
	batch 50 loss: 0.01594959992915392
	batch 75 loss: 0.015907839480787514
	batch 100 loss: 0.018672809358686208
	batch 125 loss: 0.019749010056257246
	batch 150 loss: 0.020738244354724884
	batch 175 loss: 0.017009530626237394
	batch 200 loss: 0.02098712859675288
	batch 225 loss: 0.024002092611044645
	batch 250 loss: 0.020007814075797797
	batch 275 loss: 0.015503107607364654
	batch 300 loss: 0.019754039142280817
	batch 325 loss: 0.027740329280495645
	batch 350 loss: 0.021192333586513998
	batch 375 loss: 0.023785232938826083
	batch 400 loss: 0.02022143954411149
LOSS [train: 0.02022143954411149] [valid: 0.01799162823226652] TIME [epoch: 1.53e+03 sec]
EPOCH 20:
	batch 25 loss: 0.01849428463727236
	batch 50 loss: 0.018501098677515985
	batch 75 loss: 0.01962845578789711
	batch 100 loss: 0.020911097954958678
	batch 125 loss: 0.021195214185863735
	batch 150 loss: 0.017406326942145823
	batch 175 loss: 0.021862947642803193
	batch 200 loss: 0.021281329691410066
	batch 225 loss: 0.019175864607095718
	batch 250 loss: 0.015252407230436802
	batch 275 loss: 0.022127557639032604
	batch 300 loss: 0.01942391935735941
	batch 325 loss: 0.02794907192699611
	batch 350 loss: 0.019286489225924016
	batch 375 loss: 0.017427847981452943
	batch 400 loss: 0.02297555636614561
LOSS [train: 0.02297555636614561] [valid: 0.017585871584985095] TIME [epoch: 1.53e+03 sec]
EPOCH 21:
	batch 25 loss: 0.022184727285057305
	batch 50 loss: 0.02328182406723499
	batch 75 loss: 0.022888252027332783
	batch 100 loss: 0.0251037603802979
	batch 125 loss: 0.021744345165789127
	batch 150 loss: 0.0176811408624053
	batch 175 loss: 0.016119965836405754
	batch 200 loss: 0.022551836613565683
	batch 225 loss: 0.018259559236466886
	batch 250 loss: 0.02051223285496235
	batch 275 loss: 0.024863406959921123
	batch 300 loss: 0.021208676546812057
	batch 325 loss: 0.019315199330449104
	batch 350 loss: 0.020884908735752106
	batch 375 loss: 0.017867855094373226
	batch 400 loss: 0.015381516870111227
LOSS [train: 0.015381516870111227] [valid: 0.017441646755105466] TIME [epoch: 1.53e+03 sec]
EPOCH 22:
	batch 25 loss: 0.014793436154723167
	batch 50 loss: 0.020690901521593332
	batch 75 loss: 0.021953151561319828
	batch 100 loss: 0.02391223106533289
	batch 125 loss: 0.016414043586701156
	batch 150 loss: 0.019445943366736173
	batch 175 loss: 0.02115718610584736
	batch 200 loss: 0.02231017990037799
	batch 225 loss: 0.02207596629858017
	batch 250 loss: 0.019670655950903893
	batch 275 loss: 0.017707918602973223
	batch 300 loss: 0.01956423950381577
	batch 325 loss: 0.01791058396920562
	batch 350 loss: 0.02265523888170719
	batch 375 loss: 0.021614859513938427
	batch 400 loss: 0.020035354532301427
LOSS [train: 0.020035354532301427] [valid: 0.018127108577027685] TIME [epoch: 1.53e+03 sec]
EPOCH 23:
	batch 25 loss: 0.02121590491384268
	batch 50 loss: 0.023136667497456073
	batch 75 loss: 0.022920118514448404
	batch 100 loss: 0.020394005198031664
	batch 125 loss: 0.022771662697196007
	batch 150 loss: 0.02197535688057542
	batch 175 loss: 0.02187732171267271
	batch 200 loss: 0.02040192710235715
	batch 225 loss: 0.01761365935206413
	batch 250 loss: 0.015011421721428633
	batch 275 loss: 0.016125751789659262
	batch 300 loss: 0.017596311401575804
	batch 325 loss: 0.015839249677956104
	batch 350 loss: 0.017365179378539323
	batch 375 loss: 0.021557763796299697
	batch 400 loss: 0.01762120543047786
LOSS [train: 0.01762120543047786] [valid: 0.016406562360134557] TIME [epoch: 1.52e+03 sec]
Saving model.
EPOCH 24:
	batch 25 loss: 0.022081144899129868
	batch 50 loss: 0.02339695204049349
	batch 75 loss: 0.020400507971644402
	batch 100 loss: 0.01526958454400301
	batch 125 loss: 0.020462006852030753
	batch 150 loss: 0.017575405016541482
	batch 175 loss: 0.0194563908316195
	batch 200 loss: 0.021025624498724936
	batch 225 loss: 0.019368936698883774
	batch 250 loss: 0.015954426750540734
	batch 275 loss: 0.019945617076009513
	batch 300 loss: 0.024125160444527866
	batch 325 loss: 0.017826378792524338
	batch 350 loss: 0.016121639274060726
	batch 375 loss: 0.017773193176835775
	batch 400 loss: 0.016310201101005076
LOSS [train: 0.016310201101005076] [valid: 0.01649227652275537] TIME [epoch: 1.53e+03 sec]
EPOCH 25:
	batch 25 loss: 0.019047167636454105
	batch 50 loss: 0.015589293353259563
	batch 75 loss: 0.01783243630081415
	batch 100 loss: 0.015338506158441305
	batch 125 loss: 0.02326111860573292
	batch 150 loss: 0.020363898798823356
	batch 175 loss: 0.018062753258273005
	batch 200 loss: 0.01919609436765313
	batch 225 loss: 0.013610816448926926
	batch 250 loss: 0.01811800502240658
	batch 275 loss: 0.01986691839993
	batch 300 loss: 0.01972552329301834
	batch 325 loss: 0.015282584875822068
	batch 350 loss: 0.01857871063053608
	batch 375 loss: 0.015926481522619725
	batch 400 loss: 0.021213244702666997
LOSS [train: 0.021213244702666997] [valid: 0.01611240724620681] TIME [epoch: 1.53e+03 sec]
Saving model.
EPOCH 26:
	batch 25 loss: 0.018030844405293466
	batch 50 loss: 0.015165375769138336
	batch 75 loss: 0.022211184035986663
	batch 100 loss: 0.018969374746084212
	batch 125 loss: 0.016308413669466972
	batch 150 loss: 0.013625555858016013
	batch 175 loss: 0.018973123989999296
	batch 200 loss: 0.015334369940683245
	batch 225 loss: 0.018818451315164565
	batch 250 loss: 0.016694999504834412
	batch 275 loss: 0.01478479139506817
	batch 300 loss: 0.018691763337701558
	batch 325 loss: 0.017145717106759547
	batch 350 loss: 0.018175718691200018
	batch 375 loss: 0.016270163487643003
	batch 400 loss: 0.015142426081001758
LOSS [train: 0.015142426081001758] [valid: 0.014919169712811708] TIME [epoch: 1.53e+03 sec]
Saving model.
EPOCH 27:
	batch 25 loss: 0.017840949576348065
	batch 50 loss: 0.015484723281115293
	batch 75 loss: 0.013919250145554542
	batch 100 loss: 0.016566378399729728
	batch 125 loss: 0.015897022243589163
	batch 150 loss: 0.016927394308149813
	batch 175 loss: 0.018700556792318822
	batch 200 loss: 0.01738432139158249
	batch 225 loss: 0.013484406676143408
	batch 250 loss: 0.016392341013997794
	batch 275 loss: 0.017366898749023675
	batch 300 loss: 0.015077593959867954
	batch 325 loss: 0.01495590066537261
	batch 350 loss: 0.017609925679862498
	batch 375 loss: 0.0164794809371233
	batch 400 loss: 0.015103813260793686
LOSS [train: 0.015103813260793686] [valid: 0.01428287123053451] TIME [epoch: 1.53e+03 sec]
Saving model.
EPOCH 28:
	batch 25 loss: 0.014622010812163353
	batch 50 loss: 0.013402760699391366
	batch 75 loss: 0.015982229746878147
	batch 100 loss: 0.015929476357996464
	batch 125 loss: 0.0163213381357491
	batch 150 loss: 0.014950625654309989
	batch 175 loss: 0.016484745368361472
	batch 200 loss: 0.016568682417273523
	batch 225 loss: 0.015442038364708423
	batch 250 loss: 0.012211855556815863
	batch 275 loss: 0.01589746568351984
	batch 300 loss: 0.016997401844710113
	batch 325 loss: 0.015150631740689278
	batch 350 loss: 0.01843629600480199
	batch 375 loss: 0.014893463719636202
	batch 400 loss: 0.014025776255875826
LOSS [train: 0.014025776255875826] [valid: 0.01247282822150737] TIME [epoch: 1.51e+03 sec]
Saving model.
EPOCH 29:
	batch 25 loss: 0.014382570553570985
	batch 50 loss: 0.014703688006848096
	batch 75 loss: 0.014972678665071727
	batch 100 loss: 0.017203466277569534
	batch 125 loss: 0.01470714520663023
	batch 150 loss: 0.013091574162244797
	batch 175 loss: 0.016754113603383303
	batch 200 loss: 0.015263376645743848
	batch 225 loss: 0.014727086713537573
	batch 250 loss: 0.014298175368458033
	batch 275 loss: 0.015787172690033914
	batch 300 loss: 0.0140035399235785
	batch 325 loss: 0.01612912256270647
	batch 350 loss: 0.013319167252629995
	batch 375 loss: 0.011871582847088575
	batch 400 loss: 0.013066114820539952
LOSS [train: 0.013066114820539952] [valid: 0.011345395380946382] TIME [epoch: 1.51e+03 sec]
Saving model.
EPOCH 30:
	batch 25 loss: 0.014294089116156102
	batch 50 loss: 0.015188990123569966
	batch 75 loss: 0.012438541781157254
	batch 100 loss: 0.013087145015597344
	batch 125 loss: 0.01382124200463295
	batch 150 loss: 0.01388139721006155
	batch 175 loss: 0.011747380439192056
	batch 200 loss: 0.014600986130535603
	batch 225 loss: 0.0139646134711802
	batch 250 loss: 0.015585824456065893
	batch 275 loss: 0.013103999076411127
	batch 300 loss: 0.012416794560849667
	batch 325 loss: 0.013907647859305143
	batch 350 loss: 0.012650209441781045
	batch 375 loss: 0.013621536567807197
	batch 400 loss: 0.011410122234374286
LOSS [train: 0.011410122234374286] [valid: 0.01115664864895128] TIME [epoch: 1.51e+03 sec]
Saving model.
EPOCH 31:
	batch 25 loss: 0.011428901180624961
	batch 50 loss: 0.014237048905342817
	batch 75 loss: 0.014963902272284032
	batch 100 loss: 0.013346893209964038
	batch 125 loss: 0.012721106112003326
	batch 150 loss: 0.013094423189759254
	batch 175 loss: 0.011990161407738923
	batch 200 loss: 0.012368299458175898
	batch 225 loss: 0.012167645674198866
	batch 250 loss: 0.013375735767185688
	batch 275 loss: 0.014215647224336863
	batch 300 loss: 0.012605917174369097
	batch 325 loss: 0.014423985928297044
	batch 350 loss: 0.012018245123326778
	batch 375 loss: 0.011756100542843342
	batch 400 loss: 0.010814011543989182
LOSS [train: 0.010814011543989182] [valid: 0.010262125009649025] TIME [epoch: 1.51e+03 sec]
Saving model.
EPOCH 32:
	batch 25 loss: 0.012616066262125969
	batch 50 loss: 0.01149947770871222
	batch 75 loss: 0.012891753558069468
	batch 100 loss: 0.011862032385542988
	batch 125 loss: 0.013090255297720432
	batch 150 loss: 0.012952118944376707
	batch 175 loss: 0.013191469870507717
	batch 200 loss: 0.011327167842537164
	batch 225 loss: 0.011329626590013504
	batch 250 loss: 0.011337087042629718
	batch 275 loss: 0.01249187600798905
	batch 300 loss: 0.012704266719520092
	batch 325 loss: 0.01158872427418828
	batch 350 loss: 0.012371112573891879
	batch 375 loss: 0.013422561325132847
	batch 400 loss: 0.014345549531280994
LOSS [train: 0.014345549531280994] [valid: 0.009855406666004759] TIME [epoch: 1.52e+03 sec]
Saving model.
EPOCH 33:
	batch 25 loss: 0.012676831232383848
	batch 50 loss: 0.01138023653998971
	batch 75 loss: 0.01222314292564988
	batch 100 loss: 0.010406628102064133
	batch 125 loss: 0.011978476215153933
	batch 150 loss: 0.013119045551866293
	batch 175 loss: 0.012795335492119192
	batch 200 loss: 0.011764417719095945
	batch 225 loss: 0.012800470907241106
	batch 250 loss: 0.011999667026102542
	batch 275 loss: 0.012851120084524154
	batch 300 loss: 0.013429353423416614
	batch 325 loss: 0.012434642557054757
	batch 350 loss: 0.011847397107630967
	batch 375 loss: 0.012730706892907619
	batch 400 loss: 0.011688190018758178
LOSS [train: 0.011688190018758178] [valid: 0.009507986170380416] TIME [epoch: 1.51e+03 sec]
Saving model.
EPOCH 34:
	batch 25 loss: 0.011158711947500706
	batch 50 loss: 0.010957145299762487
	batch 75 loss: 0.01313079496845603
	batch 100 loss: 0.012038221089169384
	batch 125 loss: 0.012954272348433733
	batch 150 loss: 0.011272001191973685
	batch 175 loss: 0.010496265217661858
	batch 200 loss: 0.010384902283549309
	batch 225 loss: 0.013316186498850585
	batch 250 loss: 0.012726832181215286
	batch 275 loss: 0.012334402408450842
	batch 300 loss: 0.011040618829429149
	batch 325 loss: 0.010343669392168521
	batch 350 loss: 0.014320098534226418
	batch 375 loss: 0.010928793605417013
	batch 400 loss: 0.011501992158591746
LOSS [train: 0.011501992158591746] [valid: 0.009486035889373549] TIME [epoch: 1.47e+03 sec]
Saving model.
EPOCH 35:
	batch 25 loss: 0.010922917947173118
	batch 50 loss: 0.012428571041673421
	batch 75 loss: 0.01361094618216157
	batch 100 loss: 0.01268655750900507
	batch 125 loss: 0.01242788108997047
	batch 150 loss: 0.012435862179845571
	batch 175 loss: 0.013179990071803331
	batch 200 loss: 0.010175243224948645
	batch 225 loss: 0.012944404203444719
	batch 250 loss: 0.009774116557091475
	batch 275 loss: 0.010527375899255276
	batch 300 loss: 0.011599577497690916
	batch 325 loss: 0.012816335819661618
	batch 350 loss: 0.011785168759524822
	batch 375 loss: 0.013377846088260412
	batch 400 loss: 0.011985332164913416
LOSS [train: 0.011985332164913416] [valid: 0.008599948189536613] TIME [epoch: 1.44e+03 sec]
Saving model.
EPOCH 36:
	batch 25 loss: 0.011305863484740258
	batch 50 loss: 0.011713202279061079
	batch 75 loss: 0.012794427685439586
	batch 100 loss: 0.01154316802509129
	batch 125 loss: 0.012171919448301196
	batch 150 loss: 0.010699255503714084
	batch 175 loss: 0.011565403984859586
	batch 200 loss: 0.01138822122476995
	batch 225 loss: 0.012883199360221625
	batch 250 loss: 0.011613022889941932
	batch 275 loss: 0.011415197597816586
	batch 300 loss: 0.011393020059913397
	batch 325 loss: 0.012282934319227935
	batch 350 loss: 0.011706276815384626
	batch 375 loss: 0.012123356834053993
	batch 400 loss: 0.011424296479672193
LOSS [train: 0.011424296479672193] [valid: 0.008920648620915017] TIME [epoch: 1.43e+03 sec]
EPOCH 37:
	batch 25 loss: 0.01028423304669559
	batch 50 loss: 0.011328729800879955
	batch 75 loss: 0.012196272611618042
	batch 100 loss: 0.013399864844977856
	batch 125 loss: 0.011206339467316867
	batch 150 loss: 0.01152300420217216
	batch 175 loss: 0.010088437814265489
	batch 200 loss: 0.011890177242457866
	batch 225 loss: 0.010129630165174604
	batch 250 loss: 0.013129858141764999
	batch 275 loss: 0.013666865890845656
	batch 300 loss: 0.013256417382508516
	batch 325 loss: 0.012670714315026999
	batch 350 loss: 0.012401201613247394
	batch 375 loss: 0.012299188608303667
	batch 400 loss: 0.011536778481677175
LOSS [train: 0.011536778481677175] [valid: 0.009270896473329534] TIME [epoch: 1.44e+03 sec]
EPOCH 38:
	batch 25 loss: 0.012490117009729147
	batch 50 loss: 0.011319701848551631
	batch 75 loss: 0.013814778812229634
	batch 100 loss: 0.010922932559624314
	batch 125 loss: 0.012431700322777033
	batch 150 loss: 0.012683197036385535
	batch 175 loss: 0.01186114614829421
	batch 200 loss: 0.011471695266664028
	batch 225 loss: 0.010713124666363
	batch 250 loss: 0.012742052683606744
	batch 275 loss: 0.010803414266556502
	batch 300 loss: 0.012921839077025652
	batch 325 loss: 0.011114665754139424
	batch 350 loss: 0.009165099505335093
	batch 375 loss: 0.013007562886923552
	batch 400 loss: 0.010914273839443923
LOSS [train: 0.010914273839443923] [valid: 0.010012643433825966] TIME [epoch: 1.43e+03 sec]
EPOCH 39:
	batch 25 loss: 0.013314412292093038
	batch 50 loss: 0.01282040111720562
	batch 75 loss: 0.012969959732145072
	batch 100 loss: 0.011344399191439153
	batch 125 loss: 0.009965891549363733
	batch 150 loss: 0.013143504653126001
	batch 175 loss: 0.01179996894672513
	batch 200 loss: 0.012097034575417638
	batch 225 loss: 0.01302067568525672
	batch 250 loss: 0.011384930294007063
	batch 275 loss: 0.010220220871269703
	batch 300 loss: 0.01178032879717648
	batch 325 loss: 0.011678725033998489
	batch 350 loss: 0.012470536716282368
	batch 375 loss: 0.01258512943983078
	batch 400 loss: 0.01154548735357821
LOSS [train: 0.01154548735357821] [valid: 0.009385140485392185] TIME [epoch: 1.44e+03 sec]
EPOCH 40:
	batch 25 loss: 0.01146663773804903
	batch 50 loss: 0.011534187588840722
	batch 75 loss: 0.012436279617249966
	batch 100 loss: 0.013535610772669316
	batch 125 loss: 0.013034913185983897
	batch 150 loss: 0.010668494943529368
	batch 175 loss: 0.013070455798879266
	batch 200 loss: 0.011565207932144404
	batch 225 loss: 0.01128441896289587
	batch 250 loss: 0.010662540905177592
	batch 275 loss: 0.01068867214024067
	batch 300 loss: 0.009399692406877875
	batch 325 loss: 0.010436501726508141
	batch 350 loss: 0.012454409124329687
	batch 375 loss: 0.01108977185562253
	batch 400 loss: 0.01165604510344565
LOSS [train: 0.01165604510344565] [valid: 0.008662477730043368] TIME [epoch: 1.44e+03 sec]
EPOCH 41:
	batch 25 loss: 0.011400015950202942
	batch 50 loss: 0.011512818410992623
	batch 75 loss: 0.012165193874388934
	batch 100 loss: 0.01016712230630219
	batch 125 loss: 0.012415938042104245
	batch 150 loss: 0.01196780651807785
	batch 175 loss: 0.012108170073479413
	batch 200 loss: 0.01192115142941475
	batch 225 loss: 0.011910280305892229
	batch 250 loss: 0.011454748213291168
	batch 275 loss: 0.012680374179035425
	batch 300 loss: 0.011831701630726457
	batch 325 loss: 0.012111058258451522
	batch 350 loss: 0.012453835550695657
	batch 375 loss: 0.012170716244727374
	batch 400 loss: 0.012335505150258542
LOSS [train: 0.012335505150258542] [valid: 0.008903744740988866] TIME [epoch: 1.45e+03 sec]
EPOCH 42:
	batch 25 loss: 0.012370154578238726
	batch 50 loss: 0.01028879439458251
	batch 75 loss: 0.012272729240357876
	batch 100 loss: 0.011551563059911132
	batch 125 loss: 0.011416380619630217
	batch 150 loss: 0.009771659038960934
	batch 175 loss: 0.013075982965528966
	batch 200 loss: 0.01239146176725626
	batch 225 loss: 0.01190480962395668
	batch 250 loss: 0.01054898701608181
	batch 275 loss: 0.011804969441145658
	batch 300 loss: 0.012320598736405373
	batch 325 loss: 0.010707299588248134
	batch 350 loss: 0.011984600219875574
	batch 375 loss: 0.01037279904820025
	batch 400 loss: 0.01266450909897685
LOSS [train: 0.01266450909897685] [valid: 0.009076421402581521] TIME [epoch: 1.5e+03 sec]
EPOCH 43:
	batch 25 loss: 0.010683206561952829
	batch 50 loss: 0.009406286189332605
	batch 75 loss: 0.011288268035277724
	batch 100 loss: 0.01209936006926
	batch 125 loss: 0.011336548635736108
	batch 150 loss: 0.010450863670557737
	batch 175 loss: 0.011240154691040515
	batch 200 loss: 0.01226260356605053
	batch 225 loss: 0.012221811302006245
	batch 250 loss: 0.01017538407817483
	batch 275 loss: 0.012664444334805012
	batch 300 loss: 0.01147237941622734
	batch 325 loss: 0.013509588139131666
	batch 350 loss: 0.011084858095273376
	batch 375 loss: 0.011569010000675917
	batch 400 loss: 0.009883426949381829
LOSS [train: 0.009883426949381829] [valid: 0.008530692548265505] TIME [epoch: 1.5e+03 sec]
Saving model.
EPOCH 44:
	batch 25 loss: 0.012386468411423266
	batch 50 loss: 0.012143285311758518
	batch 75 loss: 0.012942820489406585
	batch 100 loss: 0.012602886408567429
	batch 125 loss: 0.011134105520322918
	batch 150 loss: 0.010074458569288253
	batch 175 loss: 0.011400868110358715
	batch 200 loss: 0.012935736123472453
	batch 225 loss: 0.009920206973329187
	batch 250 loss: 0.01194467617198825
	batch 275 loss: 0.011064568888396025
	batch 300 loss: 0.011216987892985343
	batch 325 loss: 0.01174453081563115
	batch 350 loss: 0.012373182345181704
	batch 375 loss: 0.010867681764066219
	batch 400 loss: 0.011409505996853113
LOSS [train: 0.011409505996853113] [valid: 0.00897732524924019] TIME [epoch: 1.5e+03 sec]
EPOCH 45:
	batch 25 loss: 0.013201453816145658
	batch 50 loss: 0.012258993741124869
	batch 75 loss: 0.013638500589877367
	batch 100 loss: 0.01023180603981018
	batch 125 loss: 0.00901197075843811
	batch 150 loss: 0.010806898772716522
	batch 175 loss: 0.011333500426262617
	batch 200 loss: 0.011795528288930655
	batch 225 loss: 0.011370557155460119
	batch 250 loss: 0.010506283016875386
	batch 275 loss: 0.012135018296539783
	batch 300 loss: 0.012987156677991153
	batch 325 loss: 0.009633425995707512
	batch 350 loss: 0.013031446523964405
	batch 375 loss: 0.011484373304992914
	batch 400 loss: 0.010926990304142237
LOSS [train: 0.010926990304142237] [valid: 0.009152975266139644] TIME [epoch: 1.51e+03 sec]
EPOCH 46:
	batch 25 loss: 0.010569244688376785
	batch 50 loss: 0.0107997452840209
	batch 75 loss: 0.01208531877025962
	batch 100 loss: 0.012065230244770646
	batch 125 loss: 0.011220917366445064
	batch 150 loss: 0.011339320726692676
	batch 175 loss: 0.009308379935100674
	batch 200 loss: 0.012159076128154993
	batch 225 loss: 0.011489620190113783
	batch 250 loss: 0.011481001516804099
	batch 275 loss: 0.011576946908608079
	batch 300 loss: 0.011611871849745513
	batch 325 loss: 0.010276292860507965
	batch 350 loss: 0.01193806054070592
	batch 375 loss: 0.009978978279978037
	batch 400 loss: 0.012346719671040774
LOSS [train: 0.012346719671040774] [valid: 0.009079044946459666] TIME [epoch: 1.51e+03 sec]
EPOCH 47:
	batch 25 loss: 0.011697904923930764
	batch 50 loss: 0.011271136458963155
	batch 75 loss: 0.011610446888953447
	batch 100 loss: 0.011649248814210296
	batch 125 loss: 0.014443910885602236
	batch 150 loss: 0.009769936185330152
	batch 175 loss: 0.011420760583132506
	batch 200 loss: 0.01182543821632862
	batch 225 loss: 0.009871545070782304
	batch 250 loss: 0.01226451264694333
	batch 275 loss: 0.00985039671882987
	batch 300 loss: 0.012334192842245103
	batch 325 loss: 0.01299869142472744
	batch 350 loss: 0.011046939752995968
	batch 375 loss: 0.012781528737396002
	batch 400 loss: 0.012620414905250073
LOSS [train: 0.012620414905250073] [valid: 0.009539737616978527] TIME [epoch: 1.52e+03 sec]
EPOCH 48:
	batch 25 loss: 0.010907109193503857
	batch 50 loss: 0.01208252064883709
	batch 75 loss: 0.011851647142320872
	batch 100 loss: 0.011869837809354068
	batch 125 loss: 0.011920450078323484
	batch 150 loss: 0.012029164917767048
	batch 175 loss: 0.010969806583598257
	batch 200 loss: 0.010530004436150193
	batch 225 loss: 0.011727446224540472
	batch 250 loss: 0.012768032997846603
	batch 275 loss: 0.010737883681431413
	batch 300 loss: 0.010261284243315459
	batch 325 loss: 0.010533296018838883
	batch 350 loss: 0.011237587556242943
	batch 375 loss: 0.01072587665170431
	batch 400 loss: 0.009257219396531582
LOSS [train: 0.009257219396531582] [valid: 0.009120265723079985] TIME [epoch: 1.51e+03 sec]
EPOCH 49:
	batch 25 loss: 0.011231048833578824
	batch 50 loss: 0.009854407059028744
	batch 75 loss: 0.01109703429043293
	batch 100 loss: 0.011998558063060044
	batch 125 loss: 0.011784203303977846
	batch 150 loss: 0.012073055217042565
	batch 175 loss: 0.011444093585014343
	batch 200 loss: 0.011775561906397343
	batch 225 loss: 0.012101551163941621
	batch 250 loss: 0.010120949884876608
	batch 275 loss: 0.013133987877517938
	batch 300 loss: 0.012442304473370313
	batch 325 loss: 0.012455431818962097
	batch 350 loss: 0.011082529611885548
	batch 375 loss: 0.013513316260650754
	batch 400 loss: 0.010943607185035944
LOSS [train: 0.010943607185035944] [valid: 0.008789023436111165] TIME [epoch: 1.51e+03 sec]
EPOCH 50:
	batch 25 loss: 0.011988808633759618
	batch 50 loss: 0.010607516635209322
	batch 75 loss: 0.012897818721830845
	batch 100 loss: 0.012949985386803746
	batch 125 loss: 0.011042281966656447
	batch 150 loss: 0.011209349632263183
	batch 175 loss: 0.012053605057299138
	batch 200 loss: 0.011866403184831143
	batch 225 loss: 0.013386301742866636
	batch 250 loss: 0.011323326332494617
	batch 275 loss: 0.010836271196603775
	batch 300 loss: 0.01082247832790017
	batch 325 loss: 0.010660371370613575
	batch 350 loss: 0.010043633170425892
	batch 375 loss: 0.01170969707891345
	batch 400 loss: 0.010152430851012468
LOSS [train: 0.010152430851012468] [valid: 0.009912465766925985] TIME [epoch: 1.51e+03 sec]
Finished training in 82720.209 seconds.
