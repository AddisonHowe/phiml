Slurm job ID: 5359229
Namespace(batch_size=50, continuation='models/model5122611/model5122611_20231027_164241_49', dt=0.1, dtype='float32', learning_rate=0.001, momentum=0.9, name='model5359229', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, optimizer='rms', outdir='out/model_training/model5359229', seed=0, sigma=0.01, training_data='data/model_training_data_2', use_gpu=True, validation_data='data/model_validation_data_2')
Using device: cuda
Using seed: 3360755979
Continuing training of model models/model5122611/model5122611_20231027_164241_49
EPOCH 1:
	batch 50 loss: 0.01323663916438818
	batch 100 loss: 0.01213663473725319
	batch 150 loss: 0.010960373086854816
	batch 200 loss: 0.0120185839664191
LOSS [train: 0.0120185839664191] [valid: 0.008599478832426637] TIME [epoch: 266 sec]
Saving model.
EPOCH 2:
	batch 50 loss: 0.012069625537842512
	batch 100 loss: 0.011647345703095198
	batch 150 loss: 0.012089174371212721
	batch 200 loss: 0.0127646005153656
LOSS [train: 0.0127646005153656] [valid: 0.00985773128316699] TIME [epoch: 267 sec]
EPOCH 3:
	batch 50 loss: 0.01178235319443047
	batch 100 loss: 0.011627988535910844
	batch 150 loss: 0.011341503337025643
	batch 200 loss: 0.011843299297615885
LOSS [train: 0.011843299297615885] [valid: 0.008918659576981252] TIME [epoch: 267 sec]
EPOCH 4:
	batch 50 loss: 0.011565464111045002
	batch 100 loss: 0.011763604888692498
	batch 150 loss: 0.012235079323872924
	batch 200 loss: 0.012245763372629882
LOSS [train: 0.012245763372629882] [valid: 0.00949082493922712] TIME [epoch: 267 sec]
EPOCH 5:
	batch 50 loss: 0.011282073832117021
	batch 100 loss: 0.01176697893999517
	batch 150 loss: 0.01128574101254344
	batch 200 loss: 0.011372815389186143
LOSS [train: 0.011372815389186143] [valid: 0.009016488454896414] TIME [epoch: 266 sec]
EPOCH 6:
	batch 50 loss: 0.012151374369859696
	batch 100 loss: 0.011436741817742586
	batch 150 loss: 0.011090308167040349
	batch 200 loss: 0.01107310499995947
LOSS [train: 0.01107310499995947] [valid: 0.008765745851633255] TIME [epoch: 268 sec]
EPOCH 7:
	batch 50 loss: 0.011239973930642008
	batch 100 loss: 0.01231709474697709
	batch 150 loss: 0.011010566744953394
	batch 200 loss: 0.011850158032029868
LOSS [train: 0.011850158032029868] [valid: 0.009303357552562374] TIME [epoch: 269 sec]
EPOCH 8:
	batch 50 loss: 0.011154919704422355
	batch 100 loss: 0.011694136234000325
	batch 150 loss: 0.011447558142244817
	batch 200 loss: 0.01132574152201414
LOSS [train: 0.01132574152201414] [valid: 0.008718388725659073] TIME [epoch: 267 sec]
EPOCH 9:
	batch 50 loss: 0.011699706809595227
	batch 100 loss: 0.011741139208897949
	batch 150 loss: 0.011571482941508292
	batch 200 loss: 0.01152185478247702
LOSS [train: 0.01152185478247702] [valid: 0.008570060244286045] TIME [epoch: 269 sec]
Saving model.
EPOCH 10:
	batch 50 loss: 0.011116318148560822
	batch 100 loss: 0.011454997807741165
	batch 150 loss: 0.010757021363824606
	batch 200 loss: 0.011939602307975292
LOSS [train: 0.011939602307975292] [valid: 0.009204544403473847] TIME [epoch: 270 sec]
EPOCH 11:
	batch 50 loss: 0.011509276386350393
	batch 100 loss: 0.012139356043189765
	batch 150 loss: 0.011307284142822028
	batch 200 loss: 0.010373812494799494
LOSS [train: 0.010373812494799494] [valid: 0.009084229740255977] TIME [epoch: 260 sec]
EPOCH 12:
	batch 50 loss: 0.01112617681734264
	batch 100 loss: 0.011465621795505285
	batch 150 loss: 0.011100496342405676
	batch 200 loss: 0.01126256974413991
LOSS [train: 0.01126256974413991] [valid: 0.008787911228015826] TIME [epoch: 254 sec]
EPOCH 13:
	batch 50 loss: 0.011918187905102968
	batch 100 loss: 0.011665365975350141
	batch 150 loss: 0.012435808898881079
	batch 200 loss: 0.011466717422008514
LOSS [train: 0.011466717422008514] [valid: 0.008607735103820839] TIME [epoch: 254 sec]
EPOCH 14:
	batch 50 loss: 0.012121051838621498
	batch 100 loss: 0.010918981302529574
	batch 150 loss: 0.011309716273099185
	batch 200 loss: 0.011374986441805958
LOSS [train: 0.011374986441805958] [valid: 0.008561840629408835] TIME [epoch: 256 sec]
Saving model.
EPOCH 15:
	batch 50 loss: 0.012536683985963464
	batch 100 loss: 0.012246708758175373
	batch 150 loss: 0.011209932528436184
	batch 200 loss: 0.011208565114066005
LOSS [train: 0.011208565114066005] [valid: 0.008541274063585054] TIME [epoch: 253 sec]
Saving model.
EPOCH 16:
	batch 50 loss: 0.010547411954030394
	batch 100 loss: 0.011116779474541545
	batch 150 loss: 0.011650758301839233
	batch 200 loss: 0.01192821686156094
LOSS [train: 0.01192821686156094] [valid: 0.009697047909382188] TIME [epoch: 252 sec]
EPOCH 17:
	batch 50 loss: 0.011565658692270518
	batch 100 loss: 0.01148290972225368
	batch 150 loss: 0.01160720270127058
	batch 200 loss: 0.010513596152886748
LOSS [train: 0.010513596152886748] [valid: 0.009673222692557222] TIME [epoch: 252 sec]
EPOCH 18:
	batch 50 loss: 0.011162211121991276
	batch 100 loss: 0.011020150138065218
	batch 150 loss: 0.011422410104423762
	batch 200 loss: 0.011660795081406833
LOSS [train: 0.011660795081406833] [valid: 0.00856985667560366] TIME [epoch: 252 sec]
EPOCH 19:
	batch 50 loss: 0.012495672767981887
	batch 100 loss: 0.01051494838669896
	batch 150 loss: 0.011528547182679176
	batch 200 loss: 0.010856216801330447
LOSS [train: 0.010856216801330447] [valid: 0.009158086592166607] TIME [epoch: 252 sec]
EPOCH 20:
	batch 50 loss: 0.012046928592026234
	batch 100 loss: 0.012145319255068898
	batch 150 loss: 0.011851705703884363
	batch 200 loss: 0.011573390197008848
LOSS [train: 0.011573390197008848] [valid: 0.009421276826954757] TIME [epoch: 252 sec]
EPOCH 21:
	batch 50 loss: 0.010527044087648391
	batch 100 loss: 0.011690153153613209
	batch 150 loss: 0.011378044094890356
	batch 200 loss: 0.012037223968654871
LOSS [train: 0.012037223968654871] [valid: 0.008862575526412305] TIME [epoch: 247 sec]
EPOCH 22:
	batch 50 loss: 0.01140717658214271
	batch 100 loss: 0.011132437931373716
	batch 150 loss: 0.011621051961556076
	batch 200 loss: 0.011080918544903397
LOSS [train: 0.011080918544903397] [valid: 0.009053372268196351] TIME [epoch: 235 sec]
EPOCH 23:
	batch 50 loss: 0.011644348176196218
	batch 100 loss: 0.012028666343539954
	batch 150 loss: 0.012323000226169825
	batch 200 loss: 0.01087171720340848
LOSS [train: 0.01087171720340848] [valid: 0.008995090452663135] TIME [epoch: 235 sec]
EPOCH 24:
	batch 50 loss: 0.01067852252162993
	batch 100 loss: 0.012944848649203778
	batch 150 loss: 0.011684462251141668
	batch 200 loss: 0.011077959425747394
LOSS [train: 0.011077959425747394] [valid: 0.008643857657686264] TIME [epoch: 238 sec]
EPOCH 25:
	batch 50 loss: 0.011933736791834236
	batch 100 loss: 0.01203992129303515
	batch 150 loss: 0.01064139406196773
	batch 200 loss: 0.011456823628395795
LOSS [train: 0.011456823628395795] [valid: 0.00904718257006607] TIME [epoch: 236 sec]
EPOCH 26:
	batch 50 loss: 0.011587868500500918
	batch 100 loss: 0.01203967579640448
	batch 150 loss: 0.011797742852941155
	batch 200 loss: 0.010537224961444736
LOSS [train: 0.010537224961444736] [valid: 0.009206044558110686] TIME [epoch: 236 sec]
EPOCH 27:
	batch 50 loss: 0.0123054423276335
	batch 100 loss: 0.011371265426278114
	batch 150 loss: 0.011382922595366836
	batch 200 loss: 0.011294111460447311
LOSS [train: 0.011294111460447311] [valid: 0.009529824123213378] TIME [epoch: 237 sec]
EPOCH 28:
	batch 50 loss: 0.011392231546342373
	batch 100 loss: 0.011446869960054755
	batch 150 loss: 0.011245522014796734
	batch 200 loss: 0.010982250850647688
LOSS [train: 0.010982250850647688] [valid: 0.00916884125241874] TIME [epoch: 235 sec]
EPOCH 29:
	batch 50 loss: 0.010910763684660197
	batch 100 loss: 0.011305712377652526
	batch 150 loss: 0.01130825228523463
	batch 200 loss: 0.011092660538852215
LOSS [train: 0.011092660538852215] [valid: 0.008671705679201598] TIME [epoch: 236 sec]
EPOCH 30:
	batch 50 loss: 0.011674007922410965
	batch 100 loss: 0.012863665400072933
	batch 150 loss: 0.011213701777160167
	batch 200 loss: 0.01152158860117197
LOSS [train: 0.01152158860117197] [valid: 0.009816723445934865] TIME [epoch: 237 sec]
EPOCH 31:
	batch 50 loss: 0.012012787070125342
	batch 100 loss: 0.011737489812076092
	batch 150 loss: 0.012296969229355454
	batch 200 loss: 0.011424394608475268
LOSS [train: 0.011424394608475268] [valid: 0.008654031409605523] TIME [epoch: 239 sec]
EPOCH 32:
	batch 50 loss: 0.011895978925749659
	batch 100 loss: 0.010519091496244073
	batch 150 loss: 0.011179205868393183
	batch 200 loss: 0.010642928387969732
LOSS [train: 0.010642928387969732] [valid: 0.008559920021070866] TIME [epoch: 236 sec]
EPOCH 33:
	batch 50 loss: 0.011499449266120792
	batch 100 loss: 0.011432341011241078
	batch 150 loss: 0.011321094362065196
	batch 200 loss: 0.010996237983927131
LOSS [train: 0.010996237983927131] [valid: 0.008456034676297956] TIME [epoch: 239 sec]
Saving model.
EPOCH 34:
	batch 50 loss: 0.011375620234757662
	batch 100 loss: 0.011666534533724189
	batch 150 loss: 0.01154138439334929
	batch 200 loss: 0.011304801534861327
LOSS [train: 0.011304801534861327] [valid: 0.009322014621769388] TIME [epoch: 242 sec]
EPOCH 35:
	batch 50 loss: 0.011461042407900095
	batch 100 loss: 0.011596034783869981
	batch 150 loss: 0.011210456071421505
	batch 200 loss: 0.011612585270777345
LOSS [train: 0.011612585270777345] [valid: 0.009334949035837781] TIME [epoch: 237 sec]
EPOCH 36:
	batch 50 loss: 0.011299003986641765
	batch 100 loss: 0.011385784707963467
	batch 150 loss: 0.011865480318665505
	batch 200 loss: 0.011122098490595818
LOSS [train: 0.011122098490595818] [valid: 0.009361913922718183] TIME [epoch: 236 sec]
EPOCH 37:
	batch 50 loss: 0.011476536989212036
	batch 100 loss: 0.011502771200612187
	batch 150 loss: 0.011580173429101705
	batch 200 loss: 0.01099249885417521
LOSS [train: 0.01099249885417521] [valid: 0.00902093863405753] TIME [epoch: 240 sec]
EPOCH 38:
	batch 50 loss: 0.01088295916095376
	batch 100 loss: 0.011913635581731797
	batch 150 loss: 0.011343216188251973
	batch 200 loss: 0.011614170670509339
LOSS [train: 0.011614170670509339] [valid: 0.008932536145827423] TIME [epoch: 238 sec]
EPOCH 39:
	batch 50 loss: 0.011808861019089819
	batch 100 loss: 0.010692381439730525
	batch 150 loss: 0.01212141228839755
	batch 200 loss: 0.011166234845295548
LOSS [train: 0.011166234845295548] [valid: 0.008217485152029743] TIME [epoch: 241 sec]
Saving model.
EPOCH 40:
	batch 50 loss: 0.011491976119577885
	batch 100 loss: 0.010761207463219761
	batch 150 loss: 0.011345901237800717
	batch 200 loss: 0.011733501395210623
LOSS [train: 0.011733501395210623] [valid: 0.008108670061725812] TIME [epoch: 237 sec]
Saving model.
EPOCH 41:
	batch 50 loss: 0.011041388204321266
	batch 100 loss: 0.01117904751561582
	batch 150 loss: 0.010830670688301324
	batch 200 loss: 0.011244188183918596
LOSS [train: 0.011244188183918596] [valid: 0.008189564683683178] TIME [epoch: 236 sec]
EPOCH 42:
	batch 50 loss: 0.01042798432521522
	batch 100 loss: 0.0107985610794276
	batch 150 loss: 0.011539573669433595
	batch 200 loss: 0.011786709586158396
LOSS [train: 0.011786709586158396] [valid: 0.009492281099786245] TIME [epoch: 236 sec]
EPOCH 43:
	batch 50 loss: 0.0107254917640239
	batch 100 loss: 0.01127623493783176
	batch 150 loss: 1.2927329597994686
	batch 200 loss: 1.9286225080490111
LOSS [train: 1.9286225080490111] [valid: 2.047261910016338] TIME [epoch: 238 sec]
EPOCH 44:
	batch 50 loss: 2.0962683606147765
	batch 100 loss: 2.360582718849182
	batch 150 loss: 138.2173235988617
	batch 200 loss: 334.96764236450196
LOSS [train: 334.96764236450196] [valid: 33.42042608608802] TIME [epoch: 244 sec]
EPOCH 45:
	batch 50 loss: 35.550527057647706
	batch 100 loss: 28.85090642929077
	batch 150 loss: 9.553422236442566
	batch 200 loss: 4.327535390853882
LOSS [train: 4.327535390853882] [valid: 3.2760626047849657] TIME [epoch: 243 sec]
EPOCH 46:
	batch 50 loss: 3.9816609907150267
	batch 100 loss: 3.5469750452041624
	batch 150 loss: 3.1025180768966676
	batch 200 loss: 2.782410080432892
LOSS [train: 2.782410080432892] [valid: 2.1498381214837234] TIME [epoch: 249 sec]
EPOCH 47:
	batch 50 loss: 2.569616084098816
	batch 100 loss: 2.799128727912903
	batch 150 loss: 3.163948736190796
	batch 200 loss: 4.788703341484069
LOSS [train: 4.788703341484069] [valid: 3.7400779583801826] TIME [epoch: 245 sec]
EPOCH 48:
	batch 50 loss: 3.696546263694763
	batch 100 loss: 2.6559386396408082
	batch 150 loss: 3.080465097427368
	batch 200 loss: 2.8991786885261535
LOSS [train: 2.8991786885261535] [valid: 2.5527738648156326] TIME [epoch: 247 sec]
EPOCH 49:
	batch 50 loss: 3.7176463770866395
	batch 100 loss: 2.0641833782196044
	batch 150 loss: 2.1692925238609315
	batch 200 loss: 2.079070634841919
LOSS [train: 2.079070634841919] [valid: 1.5908557586051757] TIME [epoch: 242 sec]
EPOCH 50:
	batch 50 loss: 1.9355971121788025
	batch 100 loss: 1.9648775339126587
	batch 150 loss: 1.7617764043807984
	batch 200 loss: 1.9093130373954772
LOSS [train: 1.9093130373954772] [valid: 1.6274354130243107] TIME [epoch: 242 sec]
Finished training in 12389.225 seconds.
