Slurm job ID: 5122611
Namespace(batch_size=50, dt=0.1, dtype='float32', learning_rate=0.001, momentum=0.9, name='model5122611', ncells=100, ndims=2, nsigs=2, nsims_training=100, nsims_validation=30, num_epochs=50, optimizer='rms', outdir='out/model_training/model5122611', seed=99987, sigma=0.01, training_data='data/model_training_data_2', use_gpu=True, validation_data='data/model_validation_data_2')
Using device: cuda
EPOCH 1:
	batch 50 loss: 0.023333638226613402
	batch 100 loss: 0.025462869051843882
	batch 150 loss: 0.02051827928982675
	batch 200 loss: 0.020461815102025868
LOSS [train: 0.020461815102025868] [valid: 0.019786555125028825] TIME [epoch: 245 sec]
Saving model.
EPOCH 2:
	batch 50 loss: 0.0209001786634326
	batch 100 loss: 0.020640732012689112
	batch 150 loss: 0.021357538951560853
	batch 200 loss: 0.025080213388428092
LOSS [train: 0.025080213388428092] [valid: 0.019247783877654003] TIME [epoch: 256 sec]
Saving model.
EPOCH 3:
	batch 50 loss: 0.02072488428093493
	batch 100 loss: 0.02122583592310548
	batch 150 loss: 0.02258374878205359
	batch 200 loss: 0.023646571822464466
LOSS [train: 0.023646571822464466] [valid: 0.018589767689991276] TIME [epoch: 254 sec]
Saving model.
EPOCH 4:
	batch 50 loss: 0.02105815414339304
	batch 100 loss: 0.020513014551252127
	batch 150 loss: 0.022841763403266668
	batch 200 loss: 0.022447737259790303
LOSS [train: 0.022447737259790303] [valid: 0.019243650684317496] TIME [epoch: 254 sec]
EPOCH 5:
	batch 50 loss: 0.021873557660728692
	batch 100 loss: 0.020854917149990798
	batch 150 loss: 0.02054559165611863
	batch 200 loss: 0.021474355962127448
LOSS [train: 0.021474355962127448] [valid: 0.017212954561788743] TIME [epoch: 254 sec]
Saving model.
EPOCH 6:
	batch 50 loss: 0.01914158208295703
	batch 100 loss: 0.02025179721415043
	batch 150 loss: 0.020870067663490772
	batch 200 loss: 0.021089847115799785
LOSS [train: 0.021089847115799785] [valid: 0.018045784500039495] TIME [epoch: 253 sec]
EPOCH 7:
	batch 50 loss: 0.021499866172671318
	batch 100 loss: 0.01948969407938421
	batch 150 loss: 0.021597375804558398
	batch 200 loss: 0.019281364530324935
LOSS [train: 0.019281364530324935] [valid: 0.01786338654346764] TIME [epoch: 251 sec]
EPOCH 8:
	batch 50 loss: 0.020924120480194687
	batch 100 loss: 0.02208779450505972
	batch 150 loss: 0.019308126932010054
	batch 200 loss: 0.01939453333616257
LOSS [train: 0.01939453333616257] [valid: 0.017820767722150778] TIME [epoch: 241 sec]
EPOCH 9:
	batch 50 loss: 0.020165986428037286
	batch 100 loss: 0.019624996185302734
	batch 150 loss: 0.020461624767631293
	batch 200 loss: 0.02198965337127447
LOSS [train: 0.02198965337127447] [valid: 0.017533471706944206] TIME [epoch: 241 sec]
EPOCH 10:
	batch 50 loss: 0.021715874299407006
	batch 100 loss: 0.02102812321856618
	batch 150 loss: 0.02171659921295941
	batch 200 loss: 0.017788197174668313
LOSS [train: 0.017788197174668313] [valid: 0.017590670187443418] TIME [epoch: 241 sec]
EPOCH 11:
	batch 50 loss: 0.019303783923387528
	batch 100 loss: 0.020481078997254373
	batch 150 loss: 0.021745214546099303
	batch 200 loss: 0.02012812651693821
LOSS [train: 0.02012812651693821] [valid: 0.017559347351198084] TIME [epoch: 241 sec]
EPOCH 12:
	batch 50 loss: 0.019193547889590264
	batch 100 loss: 0.02061163993552327
	batch 150 loss: 0.02084984542801976
	batch 200 loss: 0.019953632447868585
LOSS [train: 0.019953632447868585] [valid: 0.017976242692869467] TIME [epoch: 241 sec]
EPOCH 13:
	batch 50 loss: 0.019637495558708907
	batch 100 loss: 0.01940845829434693
	batch 150 loss: 0.02184814746491611
	batch 200 loss: 0.021003324706107378
LOSS [train: 0.021003324706107378] [valid: 0.017164364694811713] TIME [epoch: 240 sec]
Saving model.
EPOCH 14:
	batch 50 loss: 0.01888127370737493
	batch 100 loss: 0.0191333070397377
	batch 150 loss: 0.02002949809655547
	batch 200 loss: 0.022164812022820116
LOSS [train: 0.022164812022820116] [valid: 0.017687654846910542] TIME [epoch: 240 sec]
EPOCH 15:
	batch 50 loss: 0.018405362581834197
	batch 100 loss: 0.019857086092233658
	batch 150 loss: 0.02130940541625023
	batch 200 loss: 0.02104254155419767
LOSS [train: 0.02104254155419767] [valid: 0.017892927078840635] TIME [epoch: 240 sec]
EPOCH 16:
	batch 50 loss: 0.021743366504088046
	batch 100 loss: 0.022009710036218166
	batch 150 loss: 0.0195155446510762
	batch 200 loss: 0.017396168066188693
LOSS [train: 0.017396168066188693] [valid: 0.017507317525451073] TIME [epoch: 240 sec]
EPOCH 17:
	batch 50 loss: 0.019966467935591935
	batch 100 loss: 0.021347629157826304
	batch 150 loss: 0.016817898452281953
	batch 200 loss: 0.021541723292320968
LOSS [train: 0.021541723292320968] [valid: 0.017639162263367324] TIME [epoch: 240 sec]
EPOCH 18:
	batch 50 loss: 0.021261815875768662
	batch 100 loss: 0.020966742541640996
	batch 150 loss: 0.01885107328183949
	batch 200 loss: 0.021266745422035455
LOSS [train: 0.021266745422035455] [valid: 0.017998827039264143] TIME [epoch: 241 sec]
EPOCH 19:
	batch 50 loss: 0.02276461897417903
	batch 100 loss: 0.01928308801725507
	batch 150 loss: 0.018146990574896337
	batch 200 loss: 0.019511428941041232
LOSS [train: 0.019511428941041232] [valid: 0.01794742950781559] TIME [epoch: 240 sec]
EPOCH 20:
	batch 50 loss: 0.021709202881902458
	batch 100 loss: 0.01921599670313299
	batch 150 loss: 0.020148438457399605
	batch 200 loss: 0.020373795852065085
LOSS [train: 0.020373795852065085] [valid: 0.01775423332049589] TIME [epoch: 240 sec]
EPOCH 21:
	batch 50 loss: 0.019872198645025492
	batch 100 loss: 0.02172181789763272
	batch 150 loss: 0.020869086477905512
	batch 200 loss: 0.019752342738211155
LOSS [train: 0.019752342738211155] [valid: 0.01867160927019237] TIME [epoch: 240 sec]
EPOCH 22:
	batch 50 loss: 0.020676115043461323
	batch 100 loss: 0.021259835697710516
	batch 150 loss: 0.018728350773453712
	batch 200 loss: 0.019925213707610964
LOSS [train: 0.019925213707610964] [valid: 0.017682031564375696] TIME [epoch: 240 sec]
EPOCH 23:
	batch 50 loss: 0.022425721678882838
	batch 100 loss: 0.019160129707306624
	batch 150 loss: 0.020083489874377847
	batch 200 loss: 0.017963357735425234
LOSS [train: 0.017963357735425234] [valid: 0.01809677978308173] TIME [epoch: 240 sec]
EPOCH 24:
	batch 50 loss: 0.020127714332193136
	batch 100 loss: 0.020030061826109887
	batch 150 loss: 0.018874942138791085
	batch 200 loss: 0.022481286246329547
LOSS [train: 0.022481286246329547] [valid: 0.017589162373527263] TIME [epoch: 240 sec]
EPOCH 25:
	batch 50 loss: 0.020215543853119015
	batch 100 loss: 0.019837963711470365
	batch 150 loss: 0.021065461486577987
	batch 200 loss: 0.020361014511436223
LOSS [train: 0.020361014511436223] [valid: 0.017624533821071965] TIME [epoch: 240 sec]
EPOCH 26:
	batch 50 loss: 0.02125423066318035
	batch 100 loss: 0.020810987381264568
	batch 150 loss: 0.019509869376197458
	batch 200 loss: 0.02045888239517808
LOSS [train: 0.02045888239517808] [valid: 0.017772327720498044] TIME [epoch: 240 sec]
EPOCH 27:
	batch 50 loss: 0.019958165735006334
	batch 100 loss: 0.020891107385978103
	batch 150 loss: 0.020478214640170335
	batch 200 loss: 0.019838224463164807
LOSS [train: 0.019838224463164807] [valid: 0.018188891378425373] TIME [epoch: 239 sec]
EPOCH 28:
	batch 50 loss: 0.019055706821382044
	batch 100 loss: 0.02193191383033991
	batch 150 loss: 0.01943661809898913
	batch 200 loss: 0.020191046874970198
LOSS [train: 0.020191046874970198] [valid: 0.017793508489072945] TIME [epoch: 240 sec]
EPOCH 29:
	batch 50 loss: 0.020869477624073624
	batch 100 loss: 0.020786137562245132
	batch 150 loss: 0.02032923385500908
	batch 200 loss: 0.018841254096478223
LOSS [train: 0.018841254096478223] [valid: 0.017604715559476364] TIME [epoch: 240 sec]
EPOCH 30:
	batch 50 loss: 0.018664974104613066
	batch 100 loss: 0.02078695161268115
	batch 150 loss: 0.021132532469928265
	batch 200 loss: 0.020079385302960873
LOSS [train: 0.020079385302960873] [valid: 0.01767965340986848] TIME [epoch: 240 sec]
EPOCH 31:
	batch 50 loss: 0.019817386670038104
	batch 100 loss: 0.017811038801446556
	batch 150 loss: 0.021141288876533507
	batch 200 loss: 0.02247824488207698
LOSS [train: 0.02247824488207698] [valid: 0.017748297971168843] TIME [epoch: 240 sec]
EPOCH 32:
	batch 50 loss: 0.02189160177484155
	batch 100 loss: 0.01985465446487069
	batch 150 loss: 0.022117465119808912
	batch 200 loss: 0.01759181385859847
LOSS [train: 0.01759181385859847] [valid: 0.017125030328073384] TIME [epoch: 240 sec]
Saving model.
EPOCH 33:
	batch 50 loss: 0.01896629001945257
	batch 100 loss: 0.020719962660223246
	batch 150 loss: 0.02246093855239451
	batch 200 loss: 0.01833079505711794
LOSS [train: 0.01833079505711794] [valid: 0.017725319785919662] TIME [epoch: 240 sec]
EPOCH 34:
	batch 50 loss: 0.020222479896619915
	batch 100 loss: 0.01941600061953068
	batch 150 loss: 0.02284981658682227
	batch 200 loss: 0.018587694866582752
LOSS [train: 0.018587694866582752] [valid: 0.017800161552925905] TIME [epoch: 240 sec]
EPOCH 35:
	batch 50 loss: 0.020384795889258386
	batch 100 loss: 0.019934339933097362
	batch 150 loss: 0.01835353179834783
	batch 200 loss: 0.02220207216218114
LOSS [train: 0.02220207216218114] [valid: 0.017430629070440774] TIME [epoch: 240 sec]
EPOCH 36:
	batch 50 loss: 0.020509026180952787
	batch 100 loss: 0.021651739701628685
	batch 150 loss: 0.01982455063611269
	batch 200 loss: 0.018801275808364153
LOSS [train: 0.018801275808364153] [valid: 0.01744527907964463] TIME [epoch: 240 sec]
EPOCH 37:
	batch 50 loss: 0.021934840409085155
	batch 100 loss: 0.021050403779372572
	batch 150 loss: 0.018679783465340733
	batch 200 loss: 0.020226867888122797
LOSS [train: 0.020226867888122797] [valid: 0.018513404319916542] TIME [epoch: 239 sec]
EPOCH 38:
	batch 50 loss: 0.021958649437874556
	batch 100 loss: 0.01895576586946845
	batch 150 loss: 0.021393618360161782
	batch 200 loss: 0.01725299993529916
LOSS [train: 0.01725299993529916] [valid: 0.017404033804875024] TIME [epoch: 240 sec]
EPOCH 39:
	batch 50 loss: 0.020563147738575937
	batch 100 loss: 0.02102289456874132
	batch 150 loss: 0.021311652110889555
	batch 200 loss: 0.01867583403363824
LOSS [train: 0.01867583403363824] [valid: 0.0175504582458719] TIME [epoch: 240 sec]
EPOCH 40:
	batch 50 loss: 0.021836421638727187
	batch 100 loss: 0.01794106248766184
	batch 150 loss: 0.021235755728557706
	batch 200 loss: 0.01903833558782935
LOSS [train: 0.01903833558782935] [valid: 0.017560038184941125] TIME [epoch: 240 sec]
EPOCH 41:
	batch 50 loss: 0.020376659519970416
	batch 100 loss: 0.018509705774486063
	batch 150 loss: 0.018569630831480027
	batch 200 loss: 0.019428334832191467
LOSS [train: 0.019428334832191467] [valid: 0.015835912154094935] TIME [epoch: 241 sec]
Saving model.
EPOCH 42:
	batch 50 loss: 0.021105386968702077
	batch 100 loss: 0.018563356827944518
	batch 150 loss: 0.01830517640337348
	batch 200 loss: 0.01877318081445992
LOSS [train: 0.01877318081445992] [valid: 0.016672234984192378] TIME [epoch: 240 sec]
EPOCH 43:
	batch 50 loss: 0.019809055663645266
	batch 100 loss: 0.01735002838075161
	batch 150 loss: 0.018831606041640043
	batch 200 loss: 0.018249075738713146
LOSS [train: 0.018249075738713146] [valid: 0.016693045779053742] TIME [epoch: 241 sec]
EPOCH 44:
	batch 50 loss: 0.01916228166781366
	batch 100 loss: 0.017239591963589193
	batch 150 loss: 0.019666852056980134
	batch 200 loss: 0.015634546149522068
LOSS [train: 0.015634546149522068] [valid: 0.015612336512519202] TIME [epoch: 241 sec]
Saving model.
EPOCH 45:
	batch 50 loss: 0.016401810888200998
	batch 100 loss: 0.0173498872295022
	batch 150 loss: 0.020563573148101567
	batch 200 loss: 0.016773971039801838
LOSS [train: 0.016773971039801838] [valid: 0.016354678264663865] TIME [epoch: 240 sec]
EPOCH 46:
	batch 50 loss: 0.015873778806999327
	batch 100 loss: 0.017838227655738594
	batch 150 loss: 0.018964841179549694
	batch 200 loss: 0.01848011365160346
LOSS [train: 0.01848011365160346] [valid: 0.015374634150066412] TIME [epoch: 240 sec]
Saving model.
EPOCH 47:
	batch 50 loss: 0.017884624702855945
	batch 100 loss: 0.016946109542623163
	batch 150 loss: 0.01584123509004712
	batch 200 loss: 0.015162294544279576
LOSS [train: 0.015162294544279576] [valid: 0.01408163134813852] TIME [epoch: 240 sec]
Saving model.
EPOCH 48:
	batch 50 loss: 0.01650230258703232
	batch 100 loss: 0.014634802285581828
	batch 150 loss: 0.014896944714710116
	batch 200 loss: 0.013150289030745626
LOSS [train: 0.013150289030745626] [valid: 0.012526596758107189] TIME [epoch: 240 sec]
Saving model.
EPOCH 49:
	batch 50 loss: 0.013617055946961045
	batch 100 loss: 0.013082587136887014
	batch 150 loss: 0.013100047269836069
	batch 200 loss: 0.011866349121555686
LOSS [train: 0.011866349121555686] [valid: 0.010434561908671943] TIME [epoch: 292 sec]
Saving model.
EPOCH 50:
	batch 50 loss: 0.01241801238618791
	batch 100 loss: 0.01302624543197453
	batch 150 loss: 0.012175100864842534
	batch 200 loss: 0.01227492505684495
LOSS [train: 0.01227492505684495] [valid: 0.009767228409570332] TIME [epoch: 315 sec]
Saving model.
Finished training in 12218.914 seconds.
